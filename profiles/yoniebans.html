
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>yoniebans - GitHub Contributions</title>
    <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
</head>
<body class="bg-gray-50 dark:bg-gray-900">
    <div id="root"><div class="max-w-7xl mx-auto p-4 space-y-6"><div class="bg-white dark:bg-gray-800 rounded-lg p-6 shadow"><div class="flex items-center justify-between"><div class="flex items-center gap-4"><img src="https://avatars.githubusercontent.com/u/5584832?u=28c7da0c5adfbd5abbc2b6e1e25e30e70cec7fbe&amp;v=4" alt="yoniebans&#x27;s avatar" class="w-16 h-16 rounded-full"/><div><h1 class="text-2xl font-bold">yoniebans</h1><div class="text-gray-600 dark:text-gray-400"><span class="font-semibold">Score: </span>69</div></div></div><div class="text-3xl font-bold text-blue-600 dark:text-blue-400">69</div></div></div><div class="bg-white dark:bg-gray-800 rounded-lg p-6 shadow"><p class="text-gray-700 dark:text-gray-300 text-sm leading-relaxed">Yoniebans is enhancing the image generation capabilities by integrating HEURIST and OPENAI options, as well as adding support for fal.ai through updated environment variables, runtime interfaces, core packages, and model providers. The focus has been on improving functionality with new features like optional API keys and distinct models for text and image generation tasks.</p></div><div class="grid grid-cols-1 md:grid-cols-4 gap-4"><div class="bg-white dark:bg-gray-800 rounded-lg p-6 shadow"><h3 class="font-semibold">Commits</h3><p class="text-2xl font-bold">15</p></div><div class="bg-white dark:bg-gray-800 rounded-lg p-6 shadow"><h3 class="font-semibold">Pull Requests</h3><p class="text-2xl font-bold">2</p></div><div class="bg-white dark:bg-gray-800 rounded-lg p-6 shadow"><h3 class="font-semibold">Issues</h3><p class="text-2xl font-bold">4</p></div><div class="bg-white dark:bg-gray-800 rounded-lg p-6 shadow"><h3 class="font-semibold">Comments</h3><p class="text-2xl font-bold">2</p></div></div><div class="space-y-4"><div class="border rounded-lg p-4"><div class="flex items-center justify-between cursor-pointer"><h3 class="font-semibold">Commits</h3><span>▶</span></div></div><div class="border rounded-lg p-4"><div class="flex items-center justify-between cursor-pointer"><h3 class="font-semibold">Pull Requests</h3><span>▶</span></div></div><div class="border rounded-lg p-4"><div class="flex items-center justify-between cursor-pointer"><h3 class="font-semibold">Issues</h3><span>▶</span></div></div><div class="border rounded-lg p-4"><div class="flex items-center justify-between cursor-pointer"><h3 class="font-semibold">Comments</h3><span>▶</span></div></div></div></div></div>
    <script>
        window.__DATA__ = {"contributor":"yoniebans","score":69,"summary":"Yoniebans is enhancing the image generation capabilities by integrating HEURIST and OPENAI options, as well as adding support for fal.ai through updated environment variables, runtime interfaces, core packages, and model providers. The focus has been on improving functionality with new features like optional API keys and distinct models for text and image generation tasks.","avatar_url":"https://avatars.githubusercontent.com/u/5584832?u=28c7da0c5adfbd5abbc2b6e1e25e30e70cec7fbe&v=4","activity":{"code":{"total_commits":15,"total_prs":2,"commits":[{"sha":"9c1e6c7cf5e9725a3d4b6dc5a64a4c420ad8f17b","message":"Merge branch 'main' into feat/add_image_text_model_provider_seperation_and_falai","created_at":"2024-11-29T07:58:40Z","additions":4328,"deletions":322,"changed_files":28},{"sha":"27542e73e9dc286229e219468385bf270c911fac","message":"added HEURIST and OPENAI as valid options for automatically enabling image generation","created_at":"2024-11-28T15:35:51Z","additions":14,"deletions":9,"changed_files":3},{"sha":"ab922fcf2b7b127cf78e000fe251bffb292c0366","message":"updated example env file for optional fal.ai vars","created_at":"2024-11-28T14:05:21Z","additions":2,"deletions":0,"changed_files":1},{"sha":"a8af53d3fc27702976c0aa84fa14a091b672aab5","message":"Merge branch 'main' into feat/add_image_text_model_provider_seperation_and_falai","created_at":"2024-11-28T12:56:47Z","additions":4855,"deletions":1658,"changed_files":155},{"sha":"01e8bb2a52d5185175b046ca1692a282cecba5a5","message":"updated plugin-image-generation environment variable checks to include fal.ai","created_at":"2024-11-28T12:01:10Z","additions":7,"deletions":2,"changed_files":1},{"sha":"99ffdfd4cbee7f9ea37383e679fad1c23c37fe51","message":"updated generation to include implementation for fal.ai image generation and leverage the new distinction between imageModelProvider and modelProvider. Have changed the checks from runtime.character.modelProvider to runtime.modelProvider as it should be set upon runtime intialisation for character","created_at":"2024-11-28T10:33:56Z","additions":6,"deletions":6,"changed_files":1},{"sha":"1f76c9b1901456a780c8171efa0826036541977b","message":"updated runtime interfact to include property for imageModelProvider","created_at":"2024-11-28T10:32:00Z","additions":63,"deletions":7,"changed_files":2},{"sha":"e1a98c582b94aea2b9ac8933dbf785ec448136e8","message":"include image generation plugin if FAL_API_KEY is present by default","created_at":"2024-11-28T10:17:45Z","additions":10,"deletions":0,"changed_files":1},{"sha":"f9d2c44c4d5c3186b90dbba0c7599d84552e2a32","message":"update core packages to include fal.ai client","created_at":"2024-11-28T10:15:23Z","additions":1,"deletions":0,"changed_files":1},{"sha":"4fc3c699bbf8175a997e8760ebd5ae7b5571af81","message":"updated imageGeneration action validate function to include check for FAL_API_KEY not that it can be used for generateImage","created_at":"2024-11-28T10:12:59Z","additions":2,"deletions":1,"changed_files":1},{"sha":"b09a795aa65c16a14acb041d38ff56776bdbb28c","message":"updateds core models to include a new entry for fal.ai","created_at":"2024-11-28T10:11:36Z","additions":20,"deletions":0,"changed_files":1},{"sha":"7d746e6cafe27526edf29985aa802e5dd11a5cdc","message":"given the option for distinction between the model being used for generateText and generateImage, added a new property for the imageModelProvider on the runtime class. This property is set to the imageModelProvider on character if present, otherwise it defaults to the model provider hence, the same model will be used for bother generateText and generateImage","created_at":"2024-11-28T10:10:22Z","additions":10,"deletions":0,"changed_files":1},{"sha":"a1f3323dd4436b8d58a9968b6bbfbc5cc0f53426","message":"updated Characters.ts in core/types to include an optional imageModelProvider allowing for use of different models between textGeneration and imageGeneration. If imageModelProvider is not set, it defaults to modelProvider and as such, functionality should remain the same. Also added another Model and ModelProviderName for fal.ai","created_at":"2024-11-28T10:06:44Z","additions":5,"deletions":0,"changed_files":1},{"sha":"c69d2da88feeba9d3c8cb45ae215adbbcb6e1611","message":"added generatedImages folder in agent to gitignore","created_at":"2024-11-26T13:30:07Z","additions":3,"deletions":2,"changed_files":2},{"sha":"a4400d7f79d6c983bb05add9095345c99b645c1d","message":"fix logging for memory similarity. at the moment we're trying to print the message similarity which is undefined. think memory similarity is what we're looking for in the .map function","created_at":"2024-11-26T13:25:43Z","additions":1,"deletions":1,"changed_files":1}],"pull_requests":[{"number":650,"title":"feat: add image text model provider separation and fal.ai integration","state":"MERGED","merged":true,"created_at":"2024-11-28T16:00:14Z","updated_at":"2024-11-29T11:48:49Z","body":"# Relates to:\r\n\r\n- https://github.com/ai16z/eliza/issues/647\r\n- https://github.com/ai16z/eliza/issues/648\r\n\r\n# Risks\r\n\r\nLow - Adds optional fal.ai integration for image generation. Existing functionality remains unchanged when new optional imageModelProvider is not set.\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\n- Adds fal.ai integration for image generation\r\n- Introduces separate optional image model provider configuration\r\n- Adds `FAL_API_KEY` and `FAL_AI_LORA_PATH` environment variables\r\n- Implements fal.ai client setup and image generation logic\r\n\r\n## What kind of change is this?\r\n\r\nFeatures (non-breaking change which adds functionality)\r\n\r\n# Documentation changes needed?\r\n\r\nMy changes require a change to the project documentation to document:\r\n\r\n- New environment variables\r\n- How to configure fal.ai image generation\r\n- Using separate model providers for text and image generation\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\n1. `agent/src/index.ts` - Updated to include image generation plugin should one of the valid image generation model api keys be included.\r\n2. `packages/core/src/generation.ts` - Review fal.ai integration. Changed to look at model provider on runtime instance. `if modelProvider = imageModelProvider`, use token otherwise use one of the image env vars set.\r\n4. `packages/core/src/models.ts` - Added new entry for FAL model\r\n5. `packages/core/src/types.ts` - Check new `imageModelProvider` type additions\r\n6. `packages/core/src/runtime.ts` - Review `imageModelProvider` implementation. Updated to set `imageModelProvider` if one is provided in character config otherwise default to `modelProvider`.\r\n\r\n## Detailed testing steps\r\n\r\n### fal ai api testing:\r\n\r\n1. Add `FAL_API_KEY` to .env\r\n2. Configure character with `imageModelProvider`: \"falai\"\r\n3. Test image generation with default settings\r\n7. Test with custom `FAL_AI_LORA_PATH`\r\n8. Verify existing providers still work when \"falai\" is not used\r\n9. Test switching between different image providers\r\n\r\n### same `modelProvider` to `imageModelProvider` tests:\r\n1. Set `OPENAI_API_KEY`\r\n2. Set `modelProvider` to \"openai\" in character config\r\n3. Both text generation and image generation goes through openai\r\n\r\n### different `modelProvider` to `imageModelProvider` tests:\r\n1. Set `OPENAI_API_KEY` & `FAL_API_KEY`\r\n2. Set `modelProvider` to \"openai\" and `imageModelProvider` to \"falai\" in character config \r\n3. text generation goes through openai and image generation goes through falai\r\n\r\n### different `modelProvider` to `imageModelProvider` tests:\r\n1. Set `OPENAI_API_KEY` & `HEURIST_API_KEY`\r\n2. Set `modelProvider` to \"openai\" and `imageModelProvider` to \"heurist\" in character config \r\n3. text generation goes through openai and image generation goes through heurist\r\n\r\n## Discord username\r\n\r\nyoniebans\r\n","files":[{"path":".env.example","additions":4,"deletions":0},{"path":"agent/src/index.ts","additions":11,"deletions":0},{"path":"packages/core/package.json","additions":1,"deletions":0},{"path":"packages/core/src/generation.ts","additions":62,"deletions":7},{"path":"packages/core/src/models.ts","additions":20,"deletions":0},{"path":"packages/core/src/runtime.ts","additions":10,"deletions":0},{"path":"packages/core/src/types.ts","additions":6,"deletions":0},{"path":"packages/plugin-image-generation/src/enviroment.ts","additions":12,"deletions":2},{"path":"packages/plugin-image-generation/src/index.ts","additions":3,"deletions":3}],"reviews":[],"comments":[]},{"number":616,"title":"fix: memory similarity log & new knowledge ingestion","state":"MERGED","merged":true,"created_at":"2024-11-26T14:00:56Z","updated_at":"2024-11-26T18:38:39Z","body":"# Relates to:\r\n\r\nhttps://github.com/ai16z/eliza/issues/615\r\nhttps://github.com/ai16z/eliza/issues/614\r\n\r\n<!-- This risks section is to be filled out before final review and merge. -->\r\n\r\n# Risks\r\n\r\nLow:\r\n- Change a `break;` to `continue;`\r\n- Use the correct object in a logging statement\r\n- Update .gitignore so the `generatedImages` folder doesn't get added to source control\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\nA couple of small changes:\r\n1. Fix the issue where new knowledge entries in character profile don't get included in agents memory db.\r\n2. Fix for memory fragment similarity score logging.\r\n3. Updated gitignore in `/agent` to ignore generated images\r\n\r\n## What kind of change is this?\r\n\r\nBug fixes (non-breaking change which fixes an issue)\r\n\r\n## Why are we doing this? Any context or related work?\r\n\r\nTo make changes to core knowledge work and log memory related search metrics correctly.\r\n\r\n# Documentation changes needed?\r\n\r\nMy changes do not require a change to the project documentation.\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\nScreenshots and replication steps for 2 bugs described in the linked issues.\r\n\r\n## Detailed testing steps\r\n\r\nSee linked issues\r\n\r\n## Discord username\r\n\r\nyoniebans\r\n","files":[{"path":"agent/.gitignore","additions":2,"deletions":1},{"path":"packages/core/src/knowledge.ts","additions":1,"deletions":1},{"path":"packages/core/src/runtime.ts","additions":1,"deletions":1}],"reviews":[],"comments":[{"author":"bmgalego","body":"looks good"}]}]},"issues":{"total_opened":4,"opened":[{"number":648,"title":"fal.ai image generation","state":"CLOSED","created_at":"2024-11-28T13:52:33Z","updated_at":"2024-12-14T07:36:18Z","body":"**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently there is no native integration for fal.ai image generation models. Users wanting to leverage fal.ai's specialized image models need to implement custom solutions.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd built-in support for fal.ai image generation models, allowing users to specify their fal.ai API key and lora path (if they have one). This would enable direct access to fal.ai's models through the existing image generation interface.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nUsing other supported providers already in codebase\r\n\r\n**Additional context**\r\n\r\nNative integration would benefit users wanting more control over the image generation capabilities.","labels":[{"name":"enhancement","color":"a2eeef","description":"New feature or request"}],"comments":[{"author":"tsubasakong","body":"Heurist has the powerful image generation models (FLUX, Stable Diffusion, and loras) too, and already exist inside the eliza. Apply the API key [here](https://dev-api-form.heurist.ai/) with referral code `ai16z` to get the key immediately.   \r\n\r\nYou can try the image generation web (https://imagine.heurist.ai/). The images are amazing! "}]},{"number":647,"title":"Optional image model provider to character and runtime","state":"CLOSED","created_at":"2024-11-28T13:47:36Z","updated_at":"2024-11-29T17:02:42Z","body":"**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, users can only select a single model provider for both text and image generation. This becomes limiting when a provider excels at text generation but offers subpar image generation capabilities, or vice versa.\r\n\r\n**Describe the solution you'd like**\r\n\r\nWe propose adding an optional image model provider setting that would take precedence over the default model provider when configured. If no image provider is specified, the system would continue using the default model provider, maintaining backward compatibility.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nWe've explored using a single provider (such as Heurist or OpenAI) for both text and image generation. While this works adequately, it limits flexibility. For instance, if you want to use a fine-tuned model from a specialized image generation service, this isn't currently possible.\r\n\r\n**Additional context**\r\n\r\nI've implemented a similar solution that allows me to use OpenAI for text generation while leveraging a custom fine-tuned model on fal.ai for image generation.\r\n","labels":[{"name":"enhancement","color":"a2eeef","description":"New feature or request"}],"comments":[{"author":"0xTomDaniel","body":"Added in #491 "}]},{"number":615,"title":"Smol one; Matched fragment log not showing similarity score","state":"CLOSED","created_at":"2024-11-26T13:50:47Z","updated_at":"2024-11-26T22:10:05Z","body":"**Describe the bug**\r\n\r\nSimilarity score not logging correctly when searching memory fragments. We're logging `message.similarity` instead of `memory.similarity` which is resulting in `undefined` for the similarity score between a message and a memory.\r\n\r\n**To Reproduce**\r\n\r\nRun the code and search for `Matched fragment:` in the logs. You will see `undefined` for the similarity score.\r\n\r\n**Expected behavior**\r\n\r\nI expect to see the similarity score for each matched memory fragment as per the code's intended logic.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n<img width=\"2232\" alt=\"Screenshot 2024-11-26 at 2 45 56 PM\" src=\"https://github.com/user-attachments/assets/af2fbd3d-c190-4da0-b535-dc24497839a9\">\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\nN/A\r\n","labels":[{"name":"bug","color":"d73a4a","description":"Something isn't working"}],"comments":[]},{"number":614,"title":"New knowledge not being ingested into agent memory after first run","state":"CLOSED","created_at":"2024-11-26T13:45:22Z","updated_at":"2024-11-26T21:11:10Z","body":"**Describe the bug**\r\n\r\nWhen adding a knowledge section in the character profile, these pieces of knowledge are taken and added to the agent memory. Once this is done, appending new knowledge to profile has no effect as the `processCharacterKnowledge()` method in `/packages/core/src/runtime.ts` breaks out of the knowledge adding loop as soon as it finds a piece of knowledge that already exists in memory.\r\n\r\n**To Reproduce**\r\n\r\nAdd a knowledge section to your character, start the character up for the first time. Stop the agent, update the knowledge and restart the agent. Check db.sqlite and you will see that no new knowledge has been added.\r\n\r\n**Expected behavior**\r\n\r\nI would expect the agent should be able to absorb new knowledge that is added to the character file on each startup. There is potentially an argument for memories associated to knowledge that no longer exist in the character file should be removed but that is more subjective.\r\n\r\n**Screenshots**\r\n\r\n<img width=\"2034\" alt=\"Screenshot 2024-11-26 at 2 44 37 PM\" src=\"https://github.com/user-attachments/assets/0b9f408f-9b1c-4b68-9219-258d992fde6a\">\r\n\r\n\r\n**Additional context**\r\n\r\nN/A\r\n","labels":[{"name":"bug","color":"d73a4a","description":"Something isn't working"}],"comments":[]}]},"engagement":{"total_comments":2,"total_reviews":0,"comments":[],"reviews":[]}}};
    </script>
    <script type="text/javascript">
        
const StatusDot = ({ status }) => {
  const colors = {
    open: 'bg-green-500',
    closed: 'bg-red-500',
    merged: 'bg-purple-500'
  };

  return React.createElement('span', {
    className: `inline-block w-2 h-2 rounded-full ${colors[status]} mr-2`
  });
};

const ActivitySection = ({ title, items = [], showStatus = false }) => {
  const [isExpanded, setIsExpanded] = React.useState(false);
  
  const getStatus = (item) => {
    if (item.state === 'merged' || (item.state === 'closed' && title === 'Pull Requests')) {
      return 'merged';
    }
    return item.state || 'open';
  };

  return React.createElement('div', { className: 'border rounded-lg p-4' },
    React.createElement('div', {
      className: 'flex items-center justify-between cursor-pointer',
      onClick: () => setIsExpanded(!isExpanded)
    },
      React.createElement('h3', { className: 'font-semibold' }, title),
      React.createElement('span', null, isExpanded ? '▼' : '▶')
    ),
    isExpanded && React.createElement('div', { className: 'mt-4 space-y-2' },
      items.map((item, index) => 
        React.createElement('div', { key: index, className: 'p-2 hover:bg-gray-50 dark:hover:bg-gray-800 rounded' },
          React.createElement('a', {
            href: item.url,
            target: '_blank',
            rel: 'noopener noreferrer',
            className: 'text-sm hover:text-blue-500 flex flex-col gap-1'
          },
            React.createElement('span', { className: 'font-medium flex items-center' },
              showStatus && React.createElement(StatusDot, { status: getStatus(item) }),
              item.message || item.title || item.body
            ),
            React.createElement('span', { className: 'text-gray-500 text-xs' },
              new Date(item.date || item.created_at).toLocaleDateString()
            )
          )
        )
      )
    )
  );
};

const StatCard = ({ name, value }) => {
  return React.createElement('div', { className: 'bg-white dark:bg-gray-800 rounded-lg p-6 shadow' },
    React.createElement('h3', { className: 'font-semibold' }, name),
    React.createElement('p', { className: 'text-2xl font-bold' }, value)
  );
};

const ContributorProfile = ({ data }) => {
  const stats = [
    { name: 'Commits', value: data.activity.code.total_commits },
    { name: 'Pull Requests', value: data.activity.code.total_prs },
    { name: 'Issues', value: data.activity.issues.total_opened },
    { name: 'Comments', value: data.activity.engagement.total_comments }
  ];

  return React.createElement('div', { className: 'max-w-7xl mx-auto p-4 space-y-6' },
    React.createElement('div', { className: 'bg-white dark:bg-gray-800 rounded-lg p-6 shadow' },
      React.createElement('div', { className: 'flex items-center justify-between' },
        React.createElement('div', { className: 'flex items-center gap-4' },
          React.createElement('img', {
            src: data.avatar_url,
            alt: `${data.contributor}'s avatar`,
            className: 'w-16 h-16 rounded-full'
          }),
          React.createElement('div', null,
            React.createElement('h1', { className: 'text-2xl font-bold' }, data.contributor),
            React.createElement('div', { className: 'text-gray-600 dark:text-gray-400' },
              React.createElement('span', { className: 'font-semibold' }, 'Score: '),
              data.score
            )
          )
        )
      )
    ),

    data.summary && React.createElement('div', { 
      className: 'bg-white dark:bg-gray-800 rounded-lg p-6 shadow'
    },
      React.createElement('p', { 
        className: 'text-gray-700 dark:text-gray-300 text-sm leading-relaxed'
      }, data.summary)
    ),

    React.createElement('div', { className: 'grid grid-cols-1 md:grid-cols-4 gap-4' },
      stats.map(stat => React.createElement(StatCard, { 
        key: stat.name,
        ...stat
      }))
    ),

    React.createElement('div', { className: 'space-y-4' },
      React.createElement(ActivitySection, {
        title: 'Commits',
        items: data.activity.code.commits
      }),
      React.createElement(ActivitySection, {
        title: 'Pull Requests',
        items: data.activity.code.pull_requests,
        showStatus: true
      }),
      React.createElement(ActivitySection, {
        title: 'Issues',
        items: data.activity.issues.opened || [],
        showStatus: true
      }),
      React.createElement(ActivitySection, {
        title: 'Comments',
        items: data.activity.engagement.comments
      })
    )
  );
};

// Initialize React root and render
const root = ReactDOM.createRoot(document.getElementById('root'));
root.render(React.createElement(ContributorProfile, { data: window.__DATA__ }));
    </script>
</body>
</html>