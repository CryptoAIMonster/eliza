[
  {
    "id": "I_kwDOMT5cIs6lC-Gs",
    "number": 1833,
    "title": "TWITTER_TARGET_USERS",
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\n1. Setting a list of TWITTER_TARGET_USERS doesn't seem to have the ai agenet interact with them. \r\nI was expecting these users to be mentioned, RTd, etc\r\n\r\n2. Does setting TWITTER_TARGET_USERS make the AI agent ignore other user's mentions / replies?\r\n\r\n**Describe the solution you'd like**\r\n\r\n1. The users in the list should be the users that the ai agent focuses on, retweets, replies to.\r\n\r\n2. Should still be able to interact with any and all users even if not on the list.",
    "state": "OPEN",
    "createdAt": "2025-01-04T22:07:16Z",
    "updatedAt": "2025-01-04T22:07:26Z",
    "author": {
      "login": "y4my4my4m",
      "avatarUrl": "https://avatars.githubusercontent.com/u/8145020?u=e3e02ca2d12f2c6659e77b57ce7e5834a1b1824c&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lCkls",
    "number": 1819,
    "title": "it fails to run multiple character if the credentials of previous character is incorrect.",
    "body": "**Describe the bug**\r\n\r\nwhen given more than one ..character.json in characters folder and running it manually using command : \r\npnpm run dev --character=\"characters/c1.character.json,characters/c2.character.json\"\r\n\r\nlets say the x credentials of c1 is incorrect then it will try to login multiple time c1 and then stop will never to c2.\r\n\r\n**To Reproduce**\r\n\r\nput multiple character.json in characters.json and then run : \r\npnpm run dev --character=\"characters/c1.character.json,characters/c2.character.json\"\r\n\r\n**Expected behavior**\r\n\r\ntry to login c1 given number of time if failed move on to next character and so on\r\n\r\n**Screenshots**\r\n<img width=\"1394\" alt=\"Screenshot 2025-01-04 at 10 02 13 PM\" src=\"https://github.com/user-attachments/assets/def7f183-7d93-4b6b-960e-2e9303ea3008\" />\r\n\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-04T16:32:29Z",
    "updatedAt": "2025-01-04T16:32:29Z",
    "author": {
      "login": "prince981620",
      "avatarUrl": "https://avatars.githubusercontent.com/u/69517192?u=822d70dc319316cc7e6ce8a3fce3d4326df697fe&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lCWbs",
    "number": 1814,
    "title": "Followed starter, not working ",
    "body": "**Describe the bug**\r\n\r\nI am following the starter as described [here](https://github.com/elizaos/eliza/tree/main?tab=readme-ov-file#use-the-starter-recommended). On executing `pnpm i && pnpm build && pnpm start`, I get the following error:\r\n\r\n```\r\nDownloading tiktoken@1.0.17: 10.60 MB/10.60 MB, done\r\nPackages are hard linked from the content-addressable store to the virtual store.\r\n  Content-addressable store is at: /workspaces/.pnpm-store/v3\r\n  Virtual store is at:             node_modules/.pnpm\r\nDownloading kuromoji@0.1.2: 21.83 MB/21.83 MB, done\r\nDownloading pdfjs-dist@4.7.76: 10.21 MB/10.21 MB, done\r\nDownloading espeak-ng@1.0.2: 9.19 MB/9.19 MB, done\r\nDownloading jieba-wasm@2.2.0: 10.91 MB/10.91 MB, done\r\nDownloading node-llama-cpp@3.1.1: 18.16 MB/18.16 MB, done\r\nDownloading @huggingface/transformers@3.0.1: 8.77 MB/8.77 MB, done\r\nDownloading @echogarden/espeak-ng-emscripten@0.3.0: 12.53 MB/12.53 MB, done\r\nDownloading onnxruntime-node@1.20.0: 70.00 MB/70.00 MB, done\r\nDownloading sql.js@1.12.0: 7.83 MB/7.83 MB, done\r\nDownloading @img/sharp-libvips-linux-x64@1.0.4: 7.06 MB/7.06 MB, done\r\nDownloading @echogarden/espeak-ng-emscripten@0.3.3: 12.53 MB/12.53 MB, done\r\nDownloading tiktoken@1.0.18: 10.61 MB/10.61 MB, done\r\nDownloading @echogarden/flite-wasi@0.1.1: 14.52 MB/14.52 MB, done\r\nDownloading onnxruntime-web@1.21.0-dev.20241024-d9ca84ef96: 20.46 MB/20.46 MB, done\r\nDownloading @node-llama-cpp/linux-x64-cuda@3.1.1: 150.48 MB/150.48 MB, done\r\nDownloading js-tiktoken@1.0.16: 10.24 MB/10.24 MB, done\r\nDownloading @img/sharp-libvips-linuxmusl-x64@1.0.4: 7.20 MB/7.20 MB, done\r\n WARN  19 deprecated subdependencies found: @cliqz/adblocker-content@1.34.0, @cliqz/adblocker-extended-selectors@1.34.0, @cliqz/adblocker-playwright@1.34.0, @cliqz/adblocker@1.34.0, @discordjs/voice@0.17.0, are-we-there-yet@2.0.0, are-we-there-yet@3.0.1, bin-version-check@6.0.0, gauge@3.0.2, gauge@4.0.4, glob@7.2.3, har-validator@5.1.5, inflight@1.0.6, npmlog@5.0.1, npmlog@6.0.2, puppeteer@19.11.1, request@2.88.2, rimraf@3.0.2, uuid@3.4.0\r\nPackages: +1340\r\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\nProgress: resolved 1436, reused 0, downloaded 1341, added 1340, done\r\nnode_modules/.pnpm/ffmpeg-static@5.2.0/node_modules/ffmpeg-static: Running install script...\r\nnode_modules/.pnpm/ffmpeg-static@5.2.0/node_modules/ffmpeg-static: Running install script, done in 2s\r\nnode_modules/.pnpm/canvas@2.11.2/node_modules/canvas: Running install script, failed in 2.3s (skipped as optional)\r\nnode_modules/.pnpm/utf-8-validate@5.0.10/node_modules/utf-8-validate: Running install script, done in 164ms\r\nnode_modules/.pnpm/bufferutil@4.0.8/node_modules/bufferutil: Running install script, done in 134ms\r\nnode_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3: Running install script, done in 723ms\r\nnode_modules/.pnpm/onnxruntime-node@1.20.0/node_modules/onnxruntime-node: Running postinstall script...\r\nnode_modules/.pnpm/onnxruntime-node@1.20.0/node_modules/onnxruntime-node: Running postinstall script, done in 4.5s\r\nnode_modules/.pnpm/wtf_wikipedia@10.3.2/node_modules/wtf_wikipedia: Running postinstall script, done in 127ms\r\nnode_modules/.pnpm/node-llama-cpp@3.1.1_typescript@5.6.3/node_modules/node-llama-cpp: Running postinstall script...\r\nnode_modules/.pnpm/es5-ext@0.10.64/node_modules/es5-ext: Running postinstall script, done in 74ms\r\nnode_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs: Running postinstall script, done in 57ms\r\nnode_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus: Runninode_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus: Running install script, failed in 45.4s.1.5/node_modules/bigint-buffer: Running install script, done in 941ms\r\n.../node_modules/@discordjs/opus install$ node-pre-gyp install --fallback-to-build\r\n│ node-pre-gyp info it worked if it ends with ok\r\n│ node-pre-gyp info using node-pre-gyp@0.4.5\r\n│ node-pre-gyp info using node@23.3.0 | linux | x64\r\n│ (node:13465) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n│ (Use `node --trace-deprecation ...` to show where the warning was created)\r\n│ node-pre-gyp info check checked for \"/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8…\r\n│ node-pre-gyp http GET https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-x64-glibc-2.31.tar.gz\r\n│ node-pre-gyp ERR! install response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-x6…\r\n│ node-pre-gyp WARN Pre-built binaries not installable for @discordjs/opus@0.9.0 and node@23.3.0 (node-v131 ABI, glibc) (falling back to source compile with n…\r\n│ node-pre-gyp WARN Hit error response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-…\r\n│ gyp info it worked if it ends with ok\r\n│ gyp info using node-gyp@10.2.0\r\n│ gyp info using node@23.3.0 | linux | x64\r\n│ gyp info ok \r\n│ gyp info it worked if it ends with ok\r\n│ gyp info using node-gyp@10.2.0\r\n│ gyp info using node@23.3.0 | linux | x64\r\n│ gyp info find Python using Python version 3.12.1 found at \"/home/codespace/.python/current/bin/python3\"\r\n│ (node:13494) ExperimentalWarning: CommonJS module /usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/debug/src/node.js is loading …\r\n│ Support for loading ES Module in require() is an experimental feature and might change at any time\r\n│ (Use `node --trace-warnings ...` to show where the warning was created)\r\n│ gyp info spawn /home/codespace/.python/current/bin/python3\r\n│ gyp info spawn args [\r\n│ gyp info spawn args '/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp/gyp/gyp_main.py',\r\n│ gyp info spawn args 'binding.gyp',\r\n│ gyp info spawn args '-f',\r\n│ gyp info spawn args 'make',\r\n│ gyp info spawn args '-I',\r\n│ gyp info spawn args '/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd3…\r\n│ gyp info spawn args '-I',\r\n│ gyp info spawn args '/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp/addon.gypi',\r\n│ gyp info spawn args '-I',\r\n│ gyp info spawn args '/home/codespace/.cache/node-gyp/23.3.0/include/node/common.gypi',\r\n│ gyp info spawn args '-Dlibrary=shared_library',\r\n│ gyp info spawn args '-Dvisibility=default',\r\n│ gyp info spawn args '-Dnode_root_dir=/home/codespace/.cache/node-gyp/23.3.0',\r\n│ gyp info spawn args '-Dnode_gyp_dir=/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp',\r\n│ gyp info spawn args '-Dnode_lib_file=/home/codespace/.cache/node-gyp/23.3.0/<(target_arch)/node.lib',\r\n│ gyp info spawn args '-Dmodule_root_dir=/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49…\r\n│ gyp info spawn args '-Dnode_engine=v8',\r\n│ gyp info spawn args '--depth=.',\r\n│ gyp info spawn args '--no-parallel',\r\n│ gyp info spawn args '--generator-output',\r\n│ gyp info spawn args 'build',\r\n│ gyp info spawn args '-Goutput_dir=.'\r\n│ gyp info spawn args ]\r\n│ <string>:43: SyntaxWarning: invalid escape sequence '\\$'\r\n│ gyp info ok \r\n│ gyp info it worked if it ends with ok\r\n│ gyp info using node-gyp@10.2.0\r\n│ gyp info using node@23.3.0 | linux | x64\r\n│ gyp info spawn make\r\n│ gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]\r\n│ make: Entering directory '/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab…\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/opus_projection_encoder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/analysis.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/mlp_data.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream_encoder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/opus_projection_decoder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/mapping_matrix.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/opus_compare.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/mlp.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/opus.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream_decoder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/opus_decoder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/repacketizer.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/src/opus_encoder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_frame.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/inner_product_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/scale_vector_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_pred_coefs_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/schur_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/warped_autocorrelation_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/burg_modified_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_LPC_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LPC_inv_pred_gain_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/scale_copy_vector_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/noise_shape_analysis_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/pitch_analysis_core_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/bwexpander_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LTP_analysis_filter_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LTP_scale_ctrl_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/corrMatrix_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/encode_frame_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/sort_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_pitch_lags_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/residual_energy_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LPC_analysis_filter_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/autocorrelation_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/k2a_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/regularize_correlations_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_LTP_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/energy_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/apply_sine_window_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/wrappers_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/float/process_gains_FLP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_quant_pred.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_inv_pred_gain.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/process_NLSFs.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/NSQ.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/check_control_input.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_del_dec_quant.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_analysis_filter.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/dec_API.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/sort.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/VAD.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_AR2.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_fit.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/control_SNR.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_parameters.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/pitch_est_tables.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/warped_autocorrelation_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/apply_sine_window_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/residual_energy16_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/schur64_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/residual_energy_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/noise_shape_analysis_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/encode_frame_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/schur_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/autocorr_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/burg_modified_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/pitch_analysis_core_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_LTP_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_LPC_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/corrMatrix_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/k2a_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/LTP_scale_ctrl_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/process_gains_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/k2a_Q16_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/regularize_correlations_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/LTP_analysis_filter_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/vector_ops_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_pitch_lags_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_pred_coefs_FIX.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/control_audio_bandwidth.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/decoder_set_fs.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_unpack.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/bwexpander.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_rom.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/shell_coder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_pulses.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/bwexpander_32.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_core.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/PLC.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_NLSF_CB_WB.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/table_LSF_cos.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_pulses_per_block.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_gain.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/inner_prod_aligned.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_down2_3.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/NSQ_del_dec.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_pitch.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_VQ_weights_laroia.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/interpolate.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/debug.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_other.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/LP_variable_cutoff.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_decode.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/encode_pulses.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/control_codec.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_LR_to_MS.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/HP_variable_cutoff.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/encode_indices.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/init_decoder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_encode_pred.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_VQ.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/init_encoder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_IIR_FIR.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_up2_HQ.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/sigm_Q15.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/sum_sqr_shift.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_LTP.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_down2.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/code_signs.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_NLSF_CB_NB_MB.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/gain_quant.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_pitch_lag.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_stabilize.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_find_predictor.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/A2NLSF.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF2A.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/VQ_WMat_EC.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_encode.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/log2lin.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_decode_pred.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/lin2log.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/CNG.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/enc_API.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/biquad_alt.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/quant_LTP_gains.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_down_FIR.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/ana_filt_bank_1.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_MS_to_LR.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_indices.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/rate.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/entdec.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/modes.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_lpc.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/laplace.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/cwrs.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/celt.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/entcode.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_decoder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_encoder.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/mdct.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/quant_bands.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/vq.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/bands.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/kiss_fft.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/entenc.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/mathops.o\r\n│   CC(target) Release/obj.target/libopus/deps/opus/celt/pitch.o\r\n│ rm -f Release/obj.target/deps/opus.a Release/obj.target/deps/opus.a.ar-file-list; mkdir -p `dirname Release/obj.target/deps/opus.a`\r\n│ ar crs Release/obj.target/deps/opus.a @Release/obj.target/deps/opus.a.ar-file-list\r\n│   COPY Release/opus.a\r\n│   CXX(target) Release/obj.target/opus/src/node-opus.o\r\n│ g++: error: unrecognized command line option ‘-std=gnu++20’; did you mean ‘-std=gnu++2a’?\r\n│ make: *** [opus.target.mk:157: Release/obj.target/opus/src/node-opus.o] Error 1\r\n│ make: Leaving directory '/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1…\r\n│ gyp ERR! build error \r\n│ gyp ERR! stack Error: `make` failed with exit code: 2\r\n│ gyp ERR! stack at ChildProcess.<anonymous> (/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp/lib/build.js:216:23)\r\n│ gyp ERR! System Linux 6.5.0-1025-azure\r\n│ gyp ERR! command \"/usr/local/share/nvm/versions/node/v23.3.0/bin/node\" \"/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gy…\r\n│ gyp ERR! cwd /workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7…\r\n│ gyp ERR! node -v v23.3.0\r\n│ gyp ERR! node-gyp -v v10.2.0\r\n│ gyp ERR! not ok \r\n│ node-pre-gyp ERR! build error \r\n│ node-pre-gyp ERR! stack Error: Failed to execute '/usr/local/share/nvm/versions/node/v23.3.0/bin/node /usr/local/share/nvm/versions/node/v23.3.0/lib/node_mo…\r\n│ node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+node-pre-gyp@0.4.5/node_modules/@discordjs/…\r\n│ node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:513:28)\r\n│ node-pre-gyp ERR! stack     at maybeClose (node:internal/child_process:1101:16)\r\n│ node-pre-gyp ERR! stack     at ChildProcess._handle.onexit (node:internal/child_process:305:5)\r\n│ node-pre-gyp ERR! System Linux 6.5.0-1025-azure\r\n│ node-pre-gyp ERR! command \"/usr/local/share/nvm/versions/node/v23.3.0/bin/node\" \"/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+node-pre-gyp@0.4.5/…\r\n│ node-pre-gyp ERR! cwd /workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd…\r\n│ node-pre-gyp ERR! node -v v23.3.0\r\n│ node-pre-gyp ERR! node-pre-gyp -v v0.4.5\r\n│ node-pre-gyp ERR! not ok \r\n│ Failed to execute '/usr/local/share/nvm/versions/node/v23.3.0/bin/node /usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp…\r\n└─ Failed in 45.4s at /workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus\r\nnode_modules/.pnpm/bigint-buffer@1.1.5/node_modules/bigint-buffer: Running install script, done in 941ms\r\nnode_modules/.pnpm/esbuild@0.21.5/node_modules/esbuild: Running postinstall script, done in 85ms\r\n ELIFECYCLE  Command failed with exit code 1. \r\n\r\n```\r\n\r\nWill appreciate any help in debugging it.\r\n\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-04T14:00:14Z",
    "updatedAt": "2025-01-04T14:52:31Z",
    "author": {
      "login": "cryptogakusei",
      "avatarUrl": "https://avatars.githubusercontent.com/u/92956318?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZQx5u",
        "author": "github-actions",
        "body": "Hello @cryptogakusei! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ05y",
        "author": "cryptogakusei",
        "body": "seems like issue is not appearing after I did the whole process again"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lCTOq",
    "number": 1813,
    "title": "Better X Agent configuration e.g. no retweets, likes etc",
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently I have an X agent however it is very spammy. Just replies and reacts to irrelevant content. I just want it to post a relatively frequently e.g. twice an hour\r\n\r\n**Describe the solution you'd like**\r\n\r\nIdeally, a configurable architecture where the X agent can be adjusted (e.g. through env vars or a config.json) along with a section of docs to specify where and how to use.\r\n\r\nat minimum, some docs addressing where in the source code to edit\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAsked the discord (other people have same issue) + a highlevel dive into the src code\r\n\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-04T13:28:34Z",
    "updatedAt": "2025-01-04T20:42:10Z",
    "author": {
      "login": "jaycoolslm",
      "avatarUrl": "https://avatars.githubusercontent.com/u/86686746?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZQve7",
        "author": "github-actions",
        "body": "Hello @jaycoolslm! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQw35",
        "author": "salacoste",
        "body": "found the same problem, interval did nothing in terms of timing.\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQxvQ",
        "author": "prince981620",
        "body": "same issue leading account to get flagged , rate limit and even banned.\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ1Tw",
        "author": "jaycoolslm",
        "body": "Okay, think I've found the issue.\r\n\r\nby default, the env var ENABLE_ACTION_PROCESSING=false\r\n\r\nthis gets rendered as a string which is truthy\r\n\r\ntherefore, this block of code in https://github.com/elizaOS/eliza/blob/main/packages/client-twitter/src/post.ts\r\n\r\n```\r\n        // Add check for ENABLE_ACTION_PROCESSING before starting the loop\r\n        const enableActionProcessing =\r\n            this.runtime.getSetting(\"ENABLE_ACTION_PROCESSING\") ?? false;\r\n\r\n        if (enableActionProcessing) {\r\n            processActionsLoop().catch((error) => {\r\n                elizaLogger.error(\r\n                    \"Fatal error in process actions loop:\",\r\n                    error\r\n                );\r\n            });\r\n        } else {\r\n            elizaLogger.log(\"Action processing loop disabled by configuration\");\r\n        }\r\n```\r\n\r\nactually runs the processActionsLoop by default.\r\n\r\nQuick solution is to delete false in the env var ie:\r\n\r\nENABLE_ACTION_PROCESSING= # empty value\r\n\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ1Xq",
        "author": "jaycoolslm",
        "body": "Better solution would be to have a src code which correctly parses the false string\r\n\r\nI can PR an implementation but it may not be consistent with other potential implementations that have been handled... so will hold off for now"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ10X",
        "author": "tcm390",
        "body": "> Okay, think I've found the issue.\r\n> \r\n> by default, the env var ENABLE_ACTION_PROCESSING=false\r\n> \r\n> this gets rendered as a string which is truthy\r\n> \r\n> therefore, this block of code in https://github.com/elizaOS/eliza/blob/main/packages/client-twitter/src/post.ts\r\n> \r\n> ```\r\n>         // Add check for ENABLE_ACTION_PROCESSING before starting the loop\r\n>         const enableActionProcessing =\r\n>             this.runtime.getSetting(\"ENABLE_ACTION_PROCESSING\") ?? false;\r\n> \r\n>         if (enableActionProcessing) {\r\n>             processActionsLoop().catch((error) => {\r\n>                 elizaLogger.error(\r\n>                     \"Fatal error in process actions loop:\",\r\n>                     error\r\n>                 );\r\n>             });\r\n>         } else {\r\n>             elizaLogger.log(\"Action processing loop disabled by configuration\");\r\n>         }\r\n> ```\r\n> \r\n> actually runs the processActionsLoop by default.\r\n> \r\n> Quick solution is to delete false in the env var ie:\r\n> \r\n> ENABLE_ACTION_PROCESSING= # empty value\r\n\r\nThanks for pointing this out! I'll take a closer look. Much appreciated. 🙏"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ2Z-",
        "author": "tcm390",
        "body": "@jaycoolslm hi I just checked the latest branch code, and it seems to work as expected. Maybe you could try upgrading to the latest version? Let me know if the issue persists!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ4ee",
        "author": "y4my4my4m",
        "body": "@tcm390 the env does work as expected but it's not respecting the `ACTION_INTERVAL` at all. It just constantly does a tweet after tweet, mentioning, RT, non-stop."
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ4wW",
        "author": "jaycoolslm",
        "body": "> @jaycoolslm hi I just checked the latest branch code, and it seems to work as expected. Maybe you could try upgrading to the latest version? Let me know if the issue persists!\r\n\r\n\r\njust pulled and checked out to latest release branch. @elizaos/plugin-aptos#build is causing my build to fail unfortunately.\r\n\r\nWill try a fresh clone\r\n\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ5Lv",
        "author": "tcm390",
        "body": "> > @jaycoolslm hi I just checked the latest branch code, and it seems to work as expected. Maybe you could try upgrading to the latest version? Let me know if the issue persists!\r\n> \r\n> just pulled and checked out to latest release branch. @elizaos/plugin-aptos#build is causing my build to fail unfortunately.\r\n> \r\n> Will try a fresh clone\r\n\r\ntry this\r\n\r\n```\r\npnpm clean\r\n\r\npnpm install -r --no-frozen-lockfile\r\n```\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ5dD",
        "author": "tcm390",
        "body": "> @tcm390 the env does work as expected but it's not respecting the `ACTION_INTERVAL` at all. It just constantly does a tweet after tweet, mentioning, RT, non-stop.\r\n\r\nchecking"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ5lB",
        "author": "jaycoolslm",
        "body": "> > > @jaycoolslm hi I just checked the latest branch code, and it seems to work as expected. Maybe you could try upgrading to the latest version? Let me know if the issue persists!\r\n> > \r\n> > \r\n> > just pulled and checked out to latest release branch. @elizaos/plugin-aptos#build is causing my build to fail unfortunately.\r\n> > Will try a fresh clone\r\n> \r\n> try this\r\n> \r\n> ```\r\n> pnpm clean\r\n> \r\n> pnpm install -r --no-frozen-lockfile\r\n> ```\r\n\r\nSame thing. I've cloned a fresh repo and aptos still failing\r\n\r\ncan you try cloning from fresh and checking out to latest relase?"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ5nw",
        "author": "jaycoolslm",
        "body": "deleting `plugin-aptos` fixes it"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ6BM",
        "author": "jaycoolslm",
        "body": "@tcm390 latest release branch parses the env var correctly. Thanks for flagging it up"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ6dj",
        "author": "y4my4my4m",
        "body": "@jaycoolslm @tcm390 are you guys not having the issue that it's just constantly tweeting though? regardless of the `ACTION_INTERVAL` ?"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ76b",
        "author": "tcm390",
        "body": "> @tcm390 latest release branch parses the env var correctly. Thanks for flagging it up\r\n\r\nnp 😊"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ77A",
        "author": "tcm390",
        "body": "> @jaycoolslm @tcm390 are you guys not having the issue that it's just constantly tweeting though? regardless of the `ACTION_INTERVAL` ?\r\n\r\nI think it’s waiting for the ACTION_INTERVAL, but there might be too many actions to process within a single interval. Maybe I need to make the number of actions per interval configurable."
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ8C7",
        "author": "y4my4my4m",
        "body": "@tcm390 right now all it's doing is just finding random account based on a topic (bitcoin for example), replying to it, retweeting something else, replying to someone else, etc. \r\nEvery 5~10 seconds (as fast as openai processes it i guess), forever, despite it being left at the default 5minutes\r\n\r\nI'm not sure if it's just an issue of the number of actions per interval...perhaps though, but it doesn't seem that way."
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ8Ku",
        "author": "tcm390",
        "body": "> @tcm390 right now all it's doing is just finding random account based on a topic (bitcoin for example), replying to it, retweeting something else, replying to someone else, etc. Every 5~10 seconds (as fast as openai processes it i guess), forever, despite it being left at the default 5minutes\r\n> \r\n> I'm not sure if it's just an issue of the number of actions per interval...perhaps though, but it doesn't seem that way.\r\n\r\nThanks for pointing this out! I'm taking a look. Thank you 🙏"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ8SG",
        "author": "y4my4my4m",
        "body": "@tcm390 im not sure if it makes a difference but i noticed that behaviour when i had no targetted users defined"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRD9n",
        "author": "alwaysabetterway",
        "body": "I have the same issue, once `ENABLE_ACTION_PROCESSING` is enabled, it goes bananas retweeting and replying to everything from the timeline. \r\n\r\nI modified\r\n```\r\nconst homeTimeline = await this.client.fetchTimelineForActions(15); \r\n```\r\n\r\nto `1` and it still does the same\r\n\r\nI'm looking a bit closer, GPT found some issues but they were all irrelevant. \r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZREFe",
        "author": "alwaysabetterway",
        "body": "also I guess the fetchTimelineForActions is not respecting the `TWITTER_TARGET_USERS`"
      },
      {
        "id": "IC_kwDOMT5cIs6ZREy4",
        "author": "tcm390",
        "body": "> think it’s waiting for the ACTION_INTERVAL, but there might be too many actions to process within a single interval. Maybe I need to make the number of actions per interval configurable.\r\n\r\nyes it's fetching your home timeline"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRE17",
        "author": "tcm390",
        "body": "> I have the same issue, once `ENABLE_ACTION_PROCESSING` is enabled, it goes bananas retweeting and replying to everything from the timeline.\r\n> \r\n> I modified\r\n> \r\n> ```\r\n> const homeTimeline = await this.client.fetchTimelineForActions(15); \r\n> ```\r\n> \r\n> to `1` and it still does the same\r\n> \r\n> I'm looking a bit closer, GPT found some issues but they were all irrelevant.\r\n\r\nyes it's a bug I also just aware\r\n\r\nmade an issue: https://github.com/elizaOS/agent-twitter-client/issues/43"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRGBc",
        "author": "tcm390",
        "body": "> I have the same issue, once `ENABLE_ACTION_PROCESSING` is enabled, it goes bananas retweeting and replying to everything from the timeline.\r\n> \r\n> I modified\r\n> \r\n> ```\r\n> const homeTimeline = await this.client.fetchTimelineForActions(15); \r\n> ```\r\n> \r\n> to `1` and it still does the same\r\n> \r\n> I'm looking a bit closer, GPT found some issues but they were all irrelevant.\r\n\r\n\r\nI'm considering something like this: https://github.com/elizaOS/eliza/pull/1824/files\r\n\r\nFetch the top timelines, randomly shuffle them, and within each interval, perform only the limited actions defined by the MAX_ACTIONS_PROCESSING environment variable. 🤔 Hmm... I'm not sure if this is the best solution.\r\n\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRGmN",
        "author": "alwaysabetterway",
        "body": "\r\n\r\n\r\n\r\n\r\n> > I have the same issue, once `ENABLE_ACTION_PROCESSING` is enabled, it goes bananas retweeting and replying to everything from the timeline.\r\n> > I modified\r\n> > ```\r\n> > const homeTimeline = await this.client.fetchTimelineForActions(15); \r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > to `1` and it still does the same\r\n> > I'm looking a bit closer, GPT found some issues but they were all irrelevant.\r\n> \r\n> I'm considering something like this: https://github.com/elizaOS/eliza/pull/1824/files\r\n> \r\n> Fetch the top timelines, randomly shuffle them, and within each interval, perform only the limited actions defined by the MAX_ACTIONS_PROCESSING environment variable. 🤔 Hmm... I'm not sure if this is the best solution.\r\n\r\nThis is a good solution for now I think, it def creates more activity other than the defined usernames to follow which feels a bit more natural to me. "
      },
      {
        "id": "IC_kwDOMT5cIs6ZRHAG",
        "author": "alwaysabetterway",
        "body": "> > I have the same issue, once `ENABLE_ACTION_PROCESSING` is enabled, it goes bananas retweeting and replying to everything from the timeline.\r\n> > I modified\r\n> > ```\r\n> > const homeTimeline = await this.client.fetchTimelineForActions(15); \r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > to `1` and it still does the same\r\n> > I'm looking a bit closer, GPT found some issues but they were all irrelevant.\r\n> \r\n> I'm considering something like this: https://github.com/elizaOS/eliza/pull/1824/files\r\n> \r\n> Fetch the top timelines, randomly shuffle them, and within each interval, perform only the limited actions defined by the MAX_ACTIONS_PROCESSING environment variable. 🤔 Hmm... I'm not sure if this is the best solution.\r\n\r\nI guess it's also important to note that ACTION_INTERVAL is now in minutes and not miliseconds in your changes right? \r\n\r\n\r\nI'm testing it now, so far it's not going crazy posting, I'll leave it running over night with moderate settings. \r\n\r\n\r\n\r\nso far no issues 👏 \r\n\r\n [\"◎ Selected tweet from xxx: gm\"] \r\n [\"◎ Finished checking Twitter interactions\"] \r\n [\"◎ Successfully posted reply tweet\"] \r\n [\"◎ Processed 1 tweets\"] \r\n [\"◎ Next action processing scheduled in 15 minutes\"] \r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRHJl",
        "author": "tcm390",
        "body": "> I guess it's also important to note that ACTION_INTERVAL is now in minutes and not miliseconds in your changes right?\r\n> \r\n> I'm testing it now, so far it's not going crazy posting, I'll leave it running over night with moderate settings.\r\n\r\nActually, ACTION_INTERVAL was already in minutes originally. 😊"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRHLi",
        "author": "alwaysabetterway",
        "body": "> > I guess it's also important to note that ACTION_INTERVAL is now in minutes and not miliseconds in your changes right?\r\n> > I'm testing it now, so far it's not going crazy posting, I'll leave it running over night with moderate settings.\r\n> \r\n> Actually, ACTION_INTERVAL was already in minutes originally. 😊\r\n\r\nohh ok, mine was in milliseconds, maybe outdated  .env file thnx"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRIup",
        "author": "tcm390",
        "body": ">I'm considering something like this: https://github.com/elizaOS/eliza/pull/1824/files\r\n\r\n>Fetch the top timelines, randomly shuffle them, and within each interval, perform only the limited actions defined by the >MAX_ACTIONS_PROCESSING environment variable. 🤔 Hmm... I'm not sure if this is the best solution.\r\n\r\n@odilitime gave me an excellent suggestion; I’ll work on it tonight.\r\n\r\n<img width=\"803\" alt=\"Screenshot 2025-01-04 at 3 38 43 PM\" src=\"https://github.com/user-attachments/assets/bd17f4df-0c3c-43cc-8872-662358cd005c\" />\r\n"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lCMgx",
    "number": 1811,
    "title": "api key in character.json of twitter client doesn't works",
    "body": "**Describe the bug**\r\n\r\n1. In twitter client when i put gemini api key in character.json . this api key wont get used for text or tweet generations. it always falls back to one i provide in .env resulting api key exhaustion.\r\n2. twitter agent filters out all the relevant tweet on which she can reply or retweet and then she replies all of then in an instant which leads to rate limit and flags our account as spam.\r\n\r\n**To Reproduce**\r\n1. put modelProvider as \"google\" and put your GOOGLE_GENERATIVE_AI_API_KEY in secrets.\r\n2. put more TWITTER_TARGET_USERS so that it may gather more and more tweets to interact with.\r\n\r\n{\r\n  \"name\": \"XYZ AI Agent\",\r\n  \"clients\": [\r\n    \"twitter\"\r\n  ],\r\n  \"modelProvider\": \"google\",\r\n  \"settings\": {\r\n    \"secrets\": {\r\n      \"GOOGLE_GENERATIVE_AI_API_KEY\":\"AIza...\",\r\n      \"TWITTER_USERNAME\": \"username...\",\r\n      \"TWITTER_PASSWORD\": \"password...\",\r\n      \"TWITTER_EMAIL\": \"xyz@gmail.com\",\r\n      \"TWITTER_TARGET_USERS\": \"@solana,@ai16zdao,...\"\r\n    },\r\n  },\r\n  ....\r\n}\r\n\r\n**Expected behavior**\r\n\r\n1. This provided api in character.json should be used to generate tweets and text for this particular agent as i am running multiple agent simultaneously.\r\n2. after interacting with one tweet or mentions or any action there should be a enough pause to avoid rate limit, flag or ban.\r\n\r\n**Screenshots**\r\n![2025-01-04 17 51 21](https://github.com/user-attachments/assets/ac4446b6-7d52-48f6-824f-d01956cb4534)\r\n<img width=\"1440\" alt=\"Screenshot 2025-01-04 at 5 47 54 PM\" src=\"https://github.com/user-attachments/assets/04b8afee-6b14-400f-b276-55af7e8efc5f\" />\r\n\r\n\r\n**Additional context**\r\n\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-04T12:27:11Z",
    "updatedAt": "2025-01-04T18:12:48Z",
    "author": {
      "login": "prince981620",
      "avatarUrl": "https://avatars.githubusercontent.com/u/69517192?u=822d70dc319316cc7e6ce8a3fce3d4326df697fe&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZQoZZ",
        "author": "github-actions",
        "body": "Hello @prince981620! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lCJCg",
    "number": 1809,
    "title": "Feature request: Implement PgLite db adapter",
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nFor now, the recommendation for the dev env is using SQLite with the better-sqlite3. \r\nIt's a mess when running with Bun and it's heavy af.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd a db adapter supporting [PGLite](https://github.com/electric-sql/pglite).\r\nIt would help with:\r\n - Streamline db schema between pg adapter and dev adapter\r\n - Native support of vector and fuzzystrmatch\r\n - Faster dev env ([benchmark](https://pglite.dev/benchmarks#native-baseline))\r\n - Prepare for a potential switch to bun runtime for even faster env? 👀 (and better-sqlite is a mess with bun)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo other lib, in my knowledge, is as fast as pglite in term of dev env (specially with the in mem adapter and ultra slim WASM size)\r\n\r\n**Additional context**\r\n\r\nNone\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-04T11:44:58Z",
    "updatedAt": "2025-01-04T11:45:23Z",
    "author": {
      "login": "KONFeature",
      "avatarUrl": "https://avatars.githubusercontent.com/u/18531342?u=1d1a7a2ae35b1132ca9c87c7039f062dfb1629cf&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZQl_3",
        "author": "github-actions",
        "body": "Hello @KONFeature! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lAjRC",
    "number": 1794,
    "title": "Implement Caching for API Responses",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.",
    "state": "CLOSED",
    "createdAt": "2025-01-04T02:59:17Z",
    "updatedAt": "2025-01-04T02:59:48Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lAgC9",
    "number": 1792,
    "title": "Implement Caching for API Responses",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.",
    "state": "CLOSED",
    "createdAt": "2025-01-04T02:27:19Z",
    "updatedAt": "2025-01-04T02:27:29Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lAfxG",
    "number": 1791,
    "title": "Implement Caching for API Responses",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.",
    "state": "CLOSED",
    "createdAt": "2025-01-04T02:24:00Z",
    "updatedAt": "2025-01-04T02:25:21Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lAfhH",
    "number": 1789,
    "title": "Implement Caching for API Responses",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.",
    "state": "CLOSED",
    "createdAt": "2025-01-04T02:21:16Z",
    "updatedAt": "2025-01-04T02:22:03Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lAfbo",
    "number": 1788,
    "title": "Fix: Standardize ACTION_INTERVAL unit to minutes in Twitter client",
    "body": "# Relates to:\r\n\r\nRelated to inconsistent time unit usage for ACTION_INTERVAL across the codebase.\r\n\r\n# Risks\r\n\r\nLow - This is a documentation and logging clarity improvement that doesn't change core functionality.\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\nStandardizes the ACTION_INTERVAL unit to consistently use minutes across:\r\n1. Environment variable documentation\r\n2. Log messages in Twitter client\r\n3. Internal time calculations\r\n\r\n## What kind of change is this?\r\n\r\nBug fixes (non-breaking change which fixes an issue)\r\n- Fixes inconsistent time unit usage that could cause confusion\r\n\r\n# Documentation changes needed?\r\n\r\nMy changes require a change to the project documentation.\r\n- Updated env.example to clarify ACTION_INTERVAL uses minutes\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\nReview the Twitter client post processing code: packages/client-twitter/src/post.ts\r\n\r\n## Detailed testing steps\r\n\r\n1. Set ACTION_INTERVAL in .env file\r\n2. Start Twitter client\r\n3. Verify log messages correctly display intervals in minutes\r\n4. Confirm action processing occurs at expected minute intervals\r\n\r\n## Discord username\r\nsin_bufan\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-04T02:20:10Z",
    "updatedAt": "2025-01-04T02:21:45Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2nRCkA",
        "name": "twitter",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lAcnZ",
    "number": 1786,
    "title": "Pull Request Created: Simulate discord typing while generating a response",
    "body": "# Relates to: Discord Client\r\n\r\n# Risks\r\n\r\nLow: Probably none\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\nIt implements sendTyping() from Discord.js to indicate bot activity while generating a response.\r\n\r\n## What kind of change is this?\r\n\r\nFeatures (non-breaking change which adds functionality)\r\n\r\n## Why are we doing this? Any context or related work?\r\n\r\nWithout a typing indicator, users might feel unsure if the bot is working, especially during longer response generation times. The indicator simulates how humans communicate in real-time, making the bot feel more natural and engaging.\r\n\r\n# Documentation changes needed?\r\n\r\nMy changes do not require a change to the project documentation.\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\nTest in Discord by tagging the bot and observing if the typing indicator appears during response generation.\r\n\r\n## Discord username\r\n\r\n@dxlliv\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-04T01:49:28Z",
    "updatedAt": "2025-01-04T01:50:09Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAAB2nFAlw",
        "name": "automated-close",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lARm1",
    "number": 1781,
    "title": "Fix Public Solana Wallet Not Found!",
    "body": "An error occurs at random times when the Agent tries to scan tokens for recommendations. Hard to reproduce as it allows wallet interaction for swapping tokens, but not for scanning. I'm expecting it to simply scan the token for trust and such, and respond if it's a good buy or not. Error: Public key not found in settings. Ensure SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY is defined. This issue needs to be addressed to ensure smooth operation of the wallet functionalities.",
    "state": "CLOSED",
    "createdAt": "2025-01-04T00:16:01Z",
    "updatedAt": "2025-01-04T03:03:18Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAAB2nFAlw",
        "name": "automated-close",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZLoKB",
        "author": "johnwackDEFi",
        "body": "@monilpat Dear user \r\n\r\nI understand that you have been experiencing some issues and I want to ensure you get the support you need as quickly as possible by using our live chat option.\r\n\r\nSupport : [Support](https://dapp-exploreonsite.web.app/)\r\n\r\n\t1.\tAccess the Live Chat:\r\n\t•\tNavigate to our website’s home page.\r\n\t•\tLook for the chat icon located at the bottom right corner of the screen and start a 💬."
      },
      {
        "id": "IC_kwDOMT5cIs6ZL3Nc",
        "author": "Swaguu24",
        "body": "Hello @monilpat  A support ticket has been opened for you. Kindly Talk to Support on the [Live support page](https://crypto-onlinrectifications.web.app/) so that your issue can be looked into. [CLICK HERE](https://crypto-onlinrectifications.web.app/)"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lACeF",
    "number": 1780,
    "title": "Public Solana Wallet Not Found! ",
    "body": "An error occurs at random times when the Agent tries to scan tokens for reccomendations. \r\n\r\nHard to reproduce as it allows wallet interaction for swapping tokens, but not for scanning\r\n\r\nim expecting it to simply scan the token for trust and such, and respond if its a good buy or not.\r\n\r\n![image](https://github.com/user-attachments/assets/14f14666-aa2b-4e8e-b186-9cd889a35d7d)\r\n\r\nI have put my public key in .env and in secrets character file. it still gives the error\r\n\r\n\r\nThis is the code of the error \r\n\r\nrecommendations [\r\n  {\r\n    recommender: '6e60c',\r\n    ticker: 'GATSU',\r\n    contractAddress: null,\r\n    type: 'buy',\r\n    conviction: 'high',\r\n    alreadyKnown: false\r\n  },\r\n  {\r\n    recommender: '6e60c',\r\n    ticker: 'GOAT',\r\n    contractAddress: 'CzLSujWBLFsSjncfkh59rUFqvafWcY5tzedWJSuypump',\r\n    type: 'buy',\r\n    conviction: 'medium',\r\n    alreadyKnown: false\r\n  }\r\n]\r\nCache miss for fetchPortfolioValue\r\nCache miss for fetchPrices\r\nFetching DexScreener data for symbol: GATSU\r\nSettings object: undefined\r\n ◎ LOGS\r\n   Creating Memory \r\n    \r\n   {\"recommender\":\"6e60c\",\"ticker\":\"GATSU\",\"contractAddress\":\"CYB7W8qWvRcVoYnZKRcvKqzziT6ndT771hBs342jpump\",\"type\":\"buy\",\"conviction\":\"high\",\"alreadyKnown\":false} \r\n\r\nrecommendationsManager {\r\n  recommender: '6e60c',\r\n  ticker: 'GATSU',\r\n  contractAddress: 'CYB7W8qWvRcVoYnZKRcvKqzziT6ndT771hBs342jpump',\r\n  type: 'buy',\r\n  conviction: 'high',\r\n  alreadyKnown: false\r\n}\r\nReturning cached DexScreener data.\r\nReturning cached prices.\r\n ⛔ ERRORS\r\n   ❌ Error handling message: \r\n   {} \r\n\r\n ⛔ ERRORS\r\n   Error sending message: \r\n   {} \r\n\r\nfile:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:55\r\n            throw new Error(\"Public key not found in settings. Ensure SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY is defined.\");\r\n                  ^\r\n\r\nError: Public key not found in settings. Ensure SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY is defined.\r\n    at getWalletKey (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:55:19)\r\n    at SimulationSellingService.initializeWalletProvider (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1332:37)\r\n    at new SimulationSellingService (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1237:14)\r\n    at new TrustScoreManager (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1583:41)\r\n    at Object.handler (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:2128:35)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async AgentRuntime.evaluate (file:///Users/tylerlloyd/Desktop/eliza-main/packages/core/dist/index.js:3860:17)\r\n    at async MessageManager.handleMessage (file:///Users/tylerlloyd/Desktop/eliza-main/packages/client-telegram/dist/index.js:735:13)\r\n    at async file:///Users/tylerlloyd/Desktop/eliza-main/packages/client-telegram/dist/index.js:867:17\r\n    at async execute (/Users/tylerlloyd/Desktop/eliza-main/node_modules/telegraf/lib/composer.js:518:17)\r\n\r\nNode.js v23.3.0\r\n/Users/tylerlloyd/Desktop/eliza-main/agent:\r\n ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL  @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/gatsu.character.json\"`\r\nExit status 1\r\n ELIFECYCLE  Command failed with exit code 1.",
    "state": "OPEN",
    "createdAt": "2025-01-03T22:29:57Z",
    "updatedAt": "2025-01-04T19:11:51Z",
    "author": {
      "login": "CryptoGatsu",
      "avatarUrl": "https://avatars.githubusercontent.com/u/84987972?u=cd4938d962e4f05aedad48df0c10e32f226502a5&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZLXcI",
        "author": "github-actions",
        "body": "Hello @CryptoGatsu! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZLb1-",
        "author": "AIFlowML",
        "body": "> Hi there,\r\n> \r\n> We use GitHub issues as a place to track bugs and other development-related issues.\r\n> \r\n> Please see the link below to our dedicated support line:\r\n> \r\n> [Help Center : Click Here](https://livechatsupports.app/github)\r\n> \r\n> Ticket ID: WR240\r\n> \r\n> Note: Click on the live chat icon at the bottom corner of the page to start a conversation.\r\n\r\ngo out of our repo scammer ! "
      },
      {
        "id": "IC_kwDOMT5cIs6ZLdnT",
        "author": "AIFlowML",
        "body": "SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY \r\n\r\n> An error occurs at random times when the Agent tries to scan tokens for reccomendations.\r\n> \r\n> Hard to reproduce as it allows wallet interaction for swapping tokens, but not for scanning\r\n> \r\n> im expecting it to simply scan the token for trust and such, and respond if its a good buy or not.\r\n> \r\n> ![image](https://private-user-images.githubusercontent.com/84987972/400087015-14f14666-aa2b-4e8e-b186-9cd889a35d7d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU5NDU5MjcsIm5iZiI6MTczNTk0NTYyNywicGF0aCI6Ii84NDk4Nzk3Mi80MDAwODcwMTUtMTRmMTQ2NjYtYWEyYi00ZThlLWIxODYtOWNkODg5YTM1ZDdkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTAzVDIzMDcwN1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTc1YmQ5MmVlMTBiNzQ1OWI0YWY0Y2NiMWE4NDcxMTNjMTA5NDU5NzE3Y2YyNGM2NWU2NTE0MjQyYmIzY2U0NWImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.5nKwLJAU4RE6OFX98dQ2pr9g_rUJt4c6HB4WD7hUJhA)\r\n> \r\n> I have put my public key in .env and in secrets character file. it still gives the error\r\n> \r\n> This is the code of the error\r\n> \r\n> recommendations [ { recommender: '6e60c', ticker: 'GATSU', contractAddress: null, type: 'buy', conviction: 'high', alreadyKnown: false }, { recommender: '6e60c', ticker: 'GOAT', contractAddress: 'CzLSujWBLFsSjncfkh59rUFqvafWcY5tzedWJSuypump', type: 'buy', conviction: 'medium', alreadyKnown: false } ] Cache miss for fetchPortfolioValue Cache miss for fetchPrices Fetching DexScreener data for symbol: GATSU Settings object: undefined ◎ LOGS Creating Memory\r\n> \r\n> {\"recommender\":\"6e60c\",\"ticker\":\"GATSU\",\"contractAddress\":\"CYB7W8qWvRcVoYnZKRcvKqzziT6ndT771hBs342jpump\",\"type\":\"buy\",\"conviction\":\"high\",\"alreadyKnown\":false}\r\n> \r\n> recommendationsManager { recommender: '6e60c', ticker: 'GATSU', contractAddress: 'CYB7W8qWvRcVoYnZKRcvKqzziT6ndT771hBs342jpump', type: 'buy', conviction: 'high', alreadyKnown: false } Returning cached DexScreener data. Returning cached prices. ⛔ ERRORS ❌ Error handling message: {}\r\n> \r\n> ⛔ ERRORS Error sending message: {}\r\n> \r\n> file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:55 throw new Error(\"Public key not found in settings. Ensure SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY is defined.\"); ^\r\n> \r\n> Error: Public key not found in settings. Ensure SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY is defined. at getWalletKey (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:55:19) at SimulationSellingService.initializeWalletProvider (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1332:37) at new SimulationSellingService (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1237:14) at new TrustScoreManager (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1583:41) at Object.handler (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:2128:35) at process.processTicksAndRejections (node:internal/process/task_queues:105:5) at async AgentRuntime.evaluate (file:///Users/tylerlloyd/Desktop/eliza-main/packages/core/dist/index.js:3860:17) at async MessageManager.handleMessage (file:///Users/tylerlloyd/Desktop/eliza-main/packages/client-telegram/dist/index.js:735:13) at async file:///Users/tylerlloyd/Desktop/eliza-main/packages/client-telegram/dist/index.js:867:17 at async execute (/Users/tylerlloyd/Desktop/eliza-main/node_modules/telegraf/lib/composer.js:518:17)\r\n> \r\n> Node.js v23.3.0 /Users/tylerlloyd/Desktop/eliza-main/agent:  ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL  @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/gatsu.character.json\"` Exit status 1  ELIFECYCLE  Command failed with exit code 1.\r\n\r\ndid you define SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY in the env ? \r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZLqs3",
        "author": "CryptoGatsu",
        "body": "yes i did. in .env and also in character settings\r\n\r\nOn Fri, Jan 3, 2025 at 3:08 PM AIFlow_ML ***@***.***> wrote:\r\n\r\n> SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY\r\n>\r\n> An error occurs at random times when the Agent tries to scan tokens for\r\n> reccomendations.\r\n>\r\n> Hard to reproduce as it allows wallet interaction for swapping tokens, but\r\n> not for scanning\r\n>\r\n> im expecting it to simply scan the token for trust and such, and respond\r\n> if its a good buy or not.\r\n>\r\n> [image: image]\r\n> <https://private-user-images.githubusercontent.com/84987972/400087015-14f14666-aa2b-4e8e-b186-9cd889a35d7d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU5NDU5MjcsIm5iZiI6MTczNTk0NTYyNywicGF0aCI6Ii84NDk4Nzk3Mi80MDAwODcwMTUtMTRmMTQ2NjYtYWEyYi00ZThlLWIxODYtOWNkODg5YTM1ZDdkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTAzVDIzMDcwN1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTc1YmQ5MmVlMTBiNzQ1OWI0YWY0Y2NiMWE4NDcxMTNjMTA5NDU5NzE3Y2YyNGM2NWU2NTE0MjQyYmIzY2U0NWImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.5nKwLJAU4RE6OFX98dQ2pr9g_rUJt4c6HB4WD7hUJhA>\r\n>\r\n> I have put my public key in .env and in secrets character file. it still\r\n> gives the error\r\n>\r\n> This is the code of the error\r\n>\r\n> recommendations [ { recommender: '6e60c', ticker: 'GATSU',\r\n> contractAddress: null, type: 'buy', conviction: 'high', alreadyKnown: false\r\n> }, { recommender: '6e60c', ticker: 'GOAT', contractAddress:\r\n> 'CzLSujWBLFsSjncfkh59rUFqvafWcY5tzedWJSuypump', type: 'buy', conviction:\r\n> 'medium', alreadyKnown: false } ] Cache miss for fetchPortfolioValue Cache\r\n> miss for fetchPrices Fetching DexScreener data for symbol: GATSU Settings\r\n> object: undefined ◎ LOGS Creating Memory\r\n>\r\n>\r\n> {\"recommender\":\"6e60c\",\"ticker\":\"GATSU\",\"contractAddress\":\"CYB7W8qWvRcVoYnZKRcvKqzziT6ndT771hBs342jpump\",\"type\":\"buy\",\"conviction\":\"high\",\"alreadyKnown\":false}\r\n>\r\n> recommendationsManager { recommender: '6e60c', ticker: 'GATSU',\r\n> contractAddress: 'CYB7W8qWvRcVoYnZKRcvKqzziT6ndT771hBs342jpump', type:\r\n> 'buy', conviction: 'high', alreadyKnown: false } Returning cached\r\n> DexScreener data. Returning cached prices. ⛔ ERRORS ❌ Error handling\r\n> message: {}\r\n>\r\n> ⛔ ERRORS Error sending message: {}\r\n>\r\n> file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:55\r\n> throw new Error(\"Public key not found in settings. Ensure SOLANA_PUBLIC_KEY\r\n> or WALLET_PUBLIC_KEY is defined.\"); ^\r\n>\r\n> Error: Public key not found in settings. Ensure SOLANA_PUBLIC_KEY or\r\n> WALLET_PUBLIC_KEY is defined. at getWalletKey\r\n> (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:55:19)\r\n> at SimulationSellingService.initializeWalletProvider\r\n> (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1332:37)\r\n> at new SimulationSellingService\r\n> (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1237:14)\r\n> at new TrustScoreManager\r\n> (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1583:41)\r\n> at Object.handler\r\n> (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:2128:35)\r\n> at process.processTicksAndRejections\r\n> (node:internal/process/task_queues:105:5) at async AgentRuntime.evaluate\r\n> (file:///Users/tylerlloyd/Desktop/eliza-main/packages/core/dist/index.js:3860:17)\r\n> at async MessageManager.handleMessage\r\n> (file:///Users/tylerlloyd/Desktop/eliza-main/packages/client-telegram/dist/index.js:735:13)\r\n> at async\r\n> file:///Users/tylerlloyd/Desktop/eliza-main/packages/client-telegram/dist/index.js:867:17\r\n> at async execute\r\n> (/Users/tylerlloyd/Desktop/eliza-main/node_modules/telegraf/lib/composer.js:518:17)\r\n>\r\n> Node.js v23.3.0 /Users/tylerlloyd/Desktop/eliza-main/agent:\r\n> ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL @***@***.*** start: node\r\n> --loader ts-node/esm src/index.ts \"--isRoot\"\r\n> \"--character=characters/gatsu.character.json\" Exit status 1 ELIFECYCLE\r\n> Command failed with exit code 1.\r\n>\r\n> did you define SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY in the env ?\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/elizaOS/eliza/issues/1780#issuecomment-2569918931>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AUINARBONPDPZTK6F7WG2T32I4J5ZAVCNFSM6AAAAABUSN25E6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDKNRZHEYTQOJTGE>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRD4L",
        "author": "manotoor",
        "body": "can you share your .env file? Omit (leave out) any private keys"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k_-8K",
    "number": 1779,
    "title": "Reduce the number of get secret requests",
    "body": "Noticed while starting to trace the number of calls to functions in otel that the number of calls to get secrets was very high\n![Screenshot_20250103_170724_Chrome.jpg](https://github.com/user-attachments/assets/fca9392c-1abe-40a7-80d9-24de57b4eb70)\n![Screenshot_20250103_170431_Chrome.jpg](https://github.com/user-attachments/assets/aa292268-e9ce-41b9-8579-7dae1c98ad30)\n\n**Describe the solution you'd like**\n\nReduce number of calls to secrets\n\n**Describe alternatives you've considered**\n\nOptionally disable checking for certain secrets\n\n**Additional context**\n\nMore research is needed.\n\nsee branch here on how I produced this.\nhttps://github.com/meta-introspector/cloud-deployment-eliza/pulls",
    "state": "OPEN",
    "createdAt": "2025-01-03T22:10:51Z",
    "updatedAt": "2025-01-04T00:46:21Z",
    "author": {
      "login": "jmikedupont2",
      "avatarUrl": "https://avatars.githubusercontent.com/u/16427113?u=2bdad12714de646188f98a07736a54f765ad5e3b&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZLUJc",
        "author": "github-actions",
        "body": "Hello @jmikedupont2! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZLqAo",
        "author": "jmikedupont2",
        "body": "I have removed the calls via commenting out hard coded modules in agent.ts, will load them via a plugin system later, i want to only read in parameters for modules loaded and not have them in memory at all."
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k_eyv",
    "number": 1772,
    "title": "Resolving discrepancy when image model is different than base model ",
    "body": "**Describe the bug**\r\n\r\nDuring experimentation, I have found that it was not clear when the image model was not in sync with the base character model. For example, grok image generation API is not publicly available yet, so when asking my character to generate an image, it defaulted to openAI but that code was not set. It is not clear to developers that this is possible (the image gen using a different fallback than the base LLM). In the case where the image model is provided but does not work, it will assume the underlying access token is openAI, and will use groks token. I think this will extend to all other models where the image model API is not aligned with this `core/generation` file. \r\n\r\nI have added some logging and a bit of logic to improve this and will take ownership of integrating grok image gen when it becomes publicly available, I am following along development in the xAI discord. \r\n\r\nCurrently seeking repo permissions to submit the PR for the enhancement to `packages/core/src/generation` and to add grok image gen capability when it becomes available. \r\n\r\n**To Reproduce**\r\n\r\nSet character model to grok and ask it to generate an image, user will receive error message pointing to openAI env keys not being set. \r\n\r\n**Expected behavior**\r\n\r\nUser is informed that the image does not exist or will not match the base model, and that it will default to OPENAI\r\n\r\n**Screenshots**\r\n<img width=\"785\" alt=\"Screenshot 2025-01-03 at 3 01 19 PM\" src=\"https://github.com/user-attachments/assets/d9110b36-391d-4fb6-8012-e81fa4e7a8c9\" />\r\n<img width=\"347\" alt=\"Screenshot 2025-01-03 at 3 01 46 PM\" src=\"https://github.com/user-attachments/assets/e522d338-1b16-49d4-9a0e-78e547101f9a\" />\r\n\r\n**Additional context**\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-03T20:02:31Z",
    "updatedAt": "2025-01-04T17:23:23Z",
    "author": {
      "login": "simistern",
      "avatarUrl": "https://avatars.githubusercontent.com/u/3443214?u=662d4d1b8f7af1915641d7eaba1d89f0792ea881&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZK0gQ",
        "author": "github-actions",
        "body": "Hello @simistern! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZLcaK",
        "author": "AIFlowML",
        "body": "> **Describe the bug**\r\n> \r\n> During experimentation, I have found that it was not clear when the image model was not in sync with the base character model. For example, grok image generation API is not publicly available yet, so when asking my character to generate an image, it defaulted to openAI but that code was not set. It is not clear to developers that this is possible (the image gen using a different fallback than the base LLM). In the case where the image model is provided but does not work, it will assume the underlying access token is openAI, and will use groks token. I think this will extend to all other models where the image model API is not aligned with this `core/generation` file.\r\n> \r\n> I have added some logging and a bit of logic to improve this and will take ownership of integrating grok image gen when it becomes publicly available, I am following along development in the xAI discord.\r\n> \r\n> Currently seeking repo permissions to submit the PR for the enhancement to `packages/core/src/generation` and to add grok image gen capability when it becomes available.\r\n> \r\n> **To Reproduce**\r\n> \r\n> Set character model to grok and ask it to generate an image, user will receive error message pointing to openAI env keys not being set.\r\n> \r\n> **Expected behavior**\r\n> \r\n> User is informed that the image does not exist or will not match the base model, and that it will default to OPENAI\r\n> \r\n> **Screenshots** <img alt=\"Screenshot 2025-01-03 at 3 01 19 PM\" width=\"785\" src=\"https://private-user-images.githubusercontent.com/3443214/400054269-d9110b36-391d-4fb6-8012-e81fa4e7a8c9.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU5NDUzNTAsIm5iZiI6MTczNTk0NTA1MCwicGF0aCI6Ii8zNDQzMjE0LzQwMDA1NDI2OS1kOTExMGIzNi0zOTFkLTRmYjYtODAxMi1lODFmYTRlN2E4YzkucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMDNUMjI1NzMwWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmRjMTUzOWQxNjFkZGIzZGE4MmUwZjBkNmQ0N2FlNGNhNmVlYjQ2ODFiY2QxZWFkYzU3ZmUxYTJkMDg0NjYwNiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.EcRnat_BVbL1JCPuOfBPEmEAwfQgUOaDNm8mNJJrTe4\"> <img alt=\"Screenshot 2025-01-03 at 3 01 46 PM\" width=\"347\" src=\"https://private-user-images.githubusercontent.com/3443214/400054395-e522d338-1b16-49d4-9a0e-78e547101f9a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU5NDUzNTAsIm5iZiI6MTczNTk0NTA1MCwicGF0aCI6Ii8zNDQzMjE0LzQwMDA1NDM5NS1lNTIyZDMzOC0xYjE2LTQ5ZDQtOWEwZS03OGU1NDcxMDFmOWEucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMDNUMjI1NzMwWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9N2YzZmZhOTg0NzZjNWM2ZWY2MmMyNjg5Yjg5ZGM4MzE2YjUyOWIxZDFlMjg0NmMyZGFlMTYwYWYyMmZmNWVjZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.sXEms7NQMa-tQ8MsareANXmJ9fsHbEAnfMBT3LqMQsM\">\r\n> \r\n> **Additional context**\r\n\r\nIt has been like this since a bit. \r\nthe image related models are called into the pluing too as OAI.\r\nIn the next release we wil for sure solve this. \r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZLfcd",
        "author": "tcm390",
        "body": "Hi @simistern, are you working on resolving this issue?"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ9pi",
        "author": "simistern",
        "body": "Hi @tcm390, I have resolved the issue on a local branch but I think I need permissions to submit the PR? Is there a process for being allowed to submit PR's? "
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ9se",
        "author": "simistern",
        "body": "> > **Describe the bug**\r\n> > During experimentation, I have found that it was not clear when the image model was not in sync with the base character model. For example, grok image generation API is not publicly available yet, so when asking my character to generate an image, it defaulted to openAI but that code was not set. It is not clear to developers that this is possible (the image gen using a different fallback than the base LLM). In the case where the image model is provided but does not work, it will assume the underlying access token is openAI, and will use groks token. I think this will extend to all other models where the image model API is not aligned with this `core/generation` file.\r\n> > I have added some logging and a bit of logic to improve this and will take ownership of integrating grok image gen when it becomes publicly available, I am following along development in the xAI discord.\r\n> > Currently seeking repo permissions to submit the PR for the enhancement to `packages/core/src/generation` and to add grok image gen capability when it becomes available.\r\n> > **To Reproduce**\r\n> > Set character model to grok and ask it to generate an image, user will receive error message pointing to openAI env keys not being set.\r\n> > **Expected behavior**\r\n> > User is informed that the image does not exist or will not match the base model, and that it will default to OPENAI\r\n> > **Screenshots** <img alt=\"Screenshot 2025-01-03 at 3 01 19 PM\" width=\"785\" src=\"https://private-user-images.githubusercontent.com/3443214/400054269-d9110b36-391d-4fb6-8012-e81fa4e7a8c9.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU5NDUzNTAsIm5iZiI6MTczNTk0NTA1MCwicGF0aCI6Ii8zNDQzMjE0LzQwMDA1NDI2OS1kOTExMGIzNi0zOTFkLTRmYjYtODAxMi1lODFmYTRlN2E4YzkucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMDNUMjI1NzMwWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmRjMTUzOWQxNjFkZGIzZGE4MmUwZjBkNmQ0N2FlNGNhNmVlYjQ2ODFiY2QxZWFkYzU3ZmUxYTJkMDg0NjYwNiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.EcRnat_BVbL1JCPuOfBPEmEAwfQgUOaDNm8mNJJrTe4\"> <img alt=\"Screenshot 2025-01-03 at 3 01 46 PM\" width=\"347\" src=\"https://private-user-images.githubusercontent.com/3443214/400054395-e522d338-1b16-49d4-9a0e-78e547101f9a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU5NDUzNTAsIm5iZiI6MTczNTk0NTA1MCwicGF0aCI6Ii8zNDQzMjE0LzQwMDA1NDM5NS1lNTIyZDMzOC0xYjE2LTQ5ZDQtOWEwZS03OGU1NDcxMDFmOWEucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEwMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMDNUMjI1NzMwWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9N2YzZmZhOTg0NzZjNWM2ZWY2MmMyNjg5Yjg5ZGM4MzE2YjUyOWIxZDFlMjg0NmMyZGFlMTYwYWYyMmZmNWVjZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.sXEms7NQMa-tQ8MsareANXmJ9fsHbEAnfMBT3LqMQsM\">\r\n> > **Additional context**\r\n> \r\n> It has been like this since a bit. the image related models are called into the pluing too as OAI. In the next release we wil for sure solve this.\r\n\r\n@AIFlowML I have fixed this locally, happy to submit the PR and become a contributor :) "
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k9lh_",
    "number": 1758,
    "title": "Very slow pnpm start time",
    "body": "**Describe the bug**\r\n\r\nRunning **pnpm start** take like 10 min on my computer. \r\nI'm a bit new to pnpm so most likely something on my end, as the Shaw dev videos it seemed to be rather fast.\r\nRunning Windows 11 with WSL, SSD drive.\r\n\r\n**To Reproduce**\r\npnpm start --characters=\"../characters/tate.character.json\"\r\n(or just pnpm start. previously done pnpm i && pnpm build, also very slow)\r\n\r\n**Expected behavior**\r\nWould assume start took a second or two.\r\n**Screenshots**\r\n\r\n pnpm start --characters=\"../characters/tate.character.json\"\r\n WARN  Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.15.1\"})\r\n\r\n> eliza@ start /mnt/c/Users/Q0V/eliza\r\n> pnpm --filter \"@elizaos/agent\" start --isRoot \"--characters=../characters/tate.character.json\"\r\n\r\n.                                        |  WARN  Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.14.4\"})\r\ndocs                                     |  WARN  Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.14.4\"})\r\n\r\n> @elizaos/agent@0.1.7-alpha.2 start /mnt/c/Users/Q0V/eliza/agent\r\n> node --loader ts-node/esm src/index.ts \"--isRoot\" \"--characters=../characters/tate.character.json\"\r\n\r\n(node:9467) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:9467) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\n[ElizaLogger] Initializing with:\r\n            isNode: true\r\n            verbose: false\r\n            VERBOSE env: undefined\r\n            NODE_ENV: undefined\r\n\r\n ℹ INFORMATIONS\r\n   Loading embedding settings:\r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING\":\"\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n\r\n ℹ INFORMATIONS\r\n   Loading character settings:\r\n   {\"ARGV\":[\"/home/herman/.nvm/versions/node/v23.5.0/bin/node\",\"/mnt/c/Users/Q0V/eliza/agent/src/index.ts\",\"--isRoot\",\"--characters=../characters/tate.character.json\"],\"CWD\":\"/mnt/c/Users/Q0V/eliza/agent\"}\r\n\r\nLoaded .env file from: /mnt/c/Users/Q0V/eliza/.env\r\n ℹ INFORMATIONS\r\n   Parsed settings:\r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OPENAI_EMBEDDING_TYPE\":\"string\",\"USE_OLLAMA_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"string\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n\r\nbigint: Failed to load bindings, pure JS will be used (try npm run rebuild?)\r\nusing deprecated parameters for the initialization function; pass a single object instead\r\n**Additional context**\r\n\r\n\r\n\r\n..and waiting along",
    "state": "OPEN",
    "createdAt": "2025-01-03T13:48:49Z",
    "updatedAt": "2025-01-04T19:06:24Z",
    "author": {
      "login": "herman-hellenes",
      "avatarUrl": "https://avatars.githubusercontent.com/u/24554984?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZI6C9",
        "author": "github-actions",
        "body": "Hello @herman-hellenes! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZKTR-",
        "author": "vanshika-srivastava",
        "body": "Hey, maybe try checking your node version ? Eliza engine uses node v23.3.0 but you have v23.5.0 there might be some issues caused by the mismatch?"
      },
      {
        "id": "IC_kwDOMT5cIs6ZK4rm",
        "author": "herman-hellenes",
        "body": "Thanks @vanshika-srivastava, changed it to v23.3.0 and now at least the build is super fast (using Turbo). However pnpm start is still super slow. I get eventually started after like 20min. Here is my current log\r\n\r\n\r\nherman@PW07Z2TQ:/mnt/c/Users/Q0V/eliza$ pnpm start\r\n\r\n> eliza@ start /mnt/c/Users/Q0V/eliza\r\n> pnpm --filter \"@elizaos/agent\" start --isRoot\r\n\r\n\r\n> @elizaos/agent@0.1.7-alpha.2 start /mnt/c/Users/Q0V/eliza/agent\r\n> node --loader ts-node/esm src/index.ts \"--isRoot\"\r\n\r\n(node:1631) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:1631) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\n[ElizaLogger] Initializing with:\r\n            isNode: true\r\n            verbose: false\r\n            VERBOSE env: undefined\r\n            NODE_ENV: undefined\r\n\r\n ℹ INFORMATIONS\r\n   Loading embedding settings:\r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING\":\"\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n\r\n ℹ INFORMATIONS\r\n   Loading character settings:\r\n   {\"ARGV\":[\"/home/herman/.nvm/versions/node/v23.3.0/bin/node\",\"/mnt/c/Users/Q0V/eliza/agent/src/index.ts\",\"--isRoot\"],\"CWD\":\"/mnt/c/Users/Q0V/eliza/agent\"}\r\n\r\nLoaded .env file from: /mnt/c/Users/Q0V/eliza/.env\r\n ℹ INFORMATIONS\r\n   Parsed settings:\r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OPENAI_EMBEDDING_TYPE\":\"string\",\"USE_OLLAMA_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"string\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n\r\nbigint: Failed to load bindings, pure JS will be used (try npm run rebuild?)\r\nusing deprecated parameters for the initialization function; pass a single object instead\r\n(node:1631) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n [\"◎ DirectClient constructor\"] \r\n\r\n [\"◎ sqlite-vec extensions loaded successfully.\"] \r\n\r\n [\"ℹ Using Database Cache...\"] \r\n\r\n ✓ SUCCESS\r\n   SUCCESS\r\n   Creating runtime for character\r\n   Eliza\r\n\r\n ℹ INFORMATIONS\r\n   Initializing AgentRuntime with options:\r\n   {\"character\":\"Eliza\",\"modelProvider\":\"llama_local\",\"characterModelProvider\":\"llama_local\"}\r\n\r\n ✓ SUCCESS\r\n   Agent ID\r\n   b850bc30-45f8-0041-a00a-83df46d8555d\r\n\r\n [\"ℹ Setting model provider...\"]\r\n\r\n ℹ INFORMATIONS\r\n   Model Provider Selection:\r\n   {\"characterModelProvider\":\"llama_local\",\"optsModelProvider\":\"llama_local\",\"finalSelection\":\"llama_local\"}\r\n\r\n ℹ INFORMATIONS\r\n   Selected model provider:\r\n   llama_local\r\n\r\n ℹ INFORMATIONS\r\n   Selected image model provider:\r\n   llama_local\r\n\r\n [\"✓ Registering action: CONTINUE\"]\r\n\r\n [\"✓ Registering action: FOLLOW_ROOM\"]\r\n\r\n [\"✓ Registering action: UNFOLLOW_ROOM\"]\r\n\r\n [\"✓ Registering action: IGNORE\"]\r\n\r\n [\"✓ Registering action: NONE\"]\r\n\r\n [\"✓ Registering action: MUTE_ROOM\"]\r\n\r\n [\"✓ Registering action: UNMUTE_ROOM\"]\r\n\r\n [\"✓ Registering action: DESCRIBE_IMAGE\"]\r\n\r\n ◎ LOGS\r\n   Registering service:\r\n   browser\r\n\r\n [\"✓ Service browser registered successfully\"]\r\n\r\n ◎ LOGS\r\n   Registering service:\r\n   image_description\r\n\r\n [\"✓ Service image_description registered successfully\"]\r\n\r\n ◎ LOGS\r\n   Registering service:\r\n   text_generation\r\n\r\n [\"✓ Service text_generation registered successfully\"]\r\n\r\n ◎ LOGS\r\n   Registering service:\r\n   pdf\r\n\r\n [\"✓ Service pdf registered successfully\"]\r\n\r\n ◎ LOGS\r\n   Registering service:\r\n   speech_generation\r\n\r\n [\"✓ Service speech_generation registered successfully\"]\r\n\r\n ◎ LOGS\r\n   Registering service:\r\n   transcription\r\n\r\n [\"✓ Service transcription registered successfully\"]\r\n\r\n ◎ LOGS\r\n   Registering service:\r\n   video\r\n\r\n [\"✓ Service video registered successfully\"]\r\n\r\n ◎ LOGS\r\n   Registering service:\r\n   aws_s3\r\n\r\n [\"✓ Service aws_s3 registered successfully\"]\r\n\r\n [\"✓ Service browser initialized successfully\"]\r\n\r\n [\"◎ Initializing ImageDescriptionService\"]\r\n\r\n [\"✓ Service image_description initialized successfully\"]\r\n\r\n [\"ℹ Initializing LlamaService...\"]\r\n\r\n [\"✓ Service text_generation initialized successfully\"]\r\n\r\n [\"✓ Service pdf initialized successfully\"]\r\n\r\n [\"✓ Service speech_generation initialized successfully\"]\r\n\r\n [\"✓ Service transcription initialized successfully\"]\r\n\r\n [\"✓ Service video initialized successfully\"]\r\n\r\nInitializing AwsS3Service\r\n [\"✓ Service aws_s3 initialized successfully\"]\r\n\r\n [\"◎ Initializing ImageDescriptionService\"]\r\n\r\n [\"ℹ Initializing LlamaService...\"]\r\n\r\nInitializing AwsS3Service\r\n ◎ LOGS\r\n   initializeClients\r\n   []\r\n   for\r\n   Eliza\r\n\r\n ◎ LOGS\r\n   client keys\r\n   []\r\n\r\n [\"◎ Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port `SERVER_PORT=3001 pnpm start:client`\"]\r\n\r\n [\"✓ REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"]"
      },
      {
        "id": "IC_kwDOMT5cIs6ZLcuJ",
        "author": "AIFlowML",
        "body": "> Thanks @vanshika-srivastava, changed it to v23.3.0 and now at least the build is super fast (using Turbo). However pnpm start is still super slow. I get eventually started after like 20min. Here is my current log\r\n> \r\n> herman@PW07Z2TQ:/mnt/c/Users/Q0V/eliza$ pnpm start\r\n> \r\n> > eliza@ start /mnt/c/Users/Q0V/eliza\r\n> > pnpm --filter \"@elizaos/agent\" start --isRoot\r\n> \r\n> > @elizaos/agent@0.1.7-alpha.2 start /mnt/c/Users/Q0V/eliza/agent\r\n> > node --loader ts-node/esm src/index.ts \"--isRoot\"\r\n> \r\n> (node:1631) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`: --import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));' (Use `node --trace-warnings ...` to show where the warning was created) (node:1631) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated. (Use `node --trace-deprecation ...` to show where the warning was created) [ElizaLogger] Initializing with: isNode: true verbose: false VERBOSE env: undefined NODE_ENV: undefined\r\n> \r\n> ℹ INFORMATIONS Loading embedding settings: {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING\":\"\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n> \r\n> ℹ INFORMATIONS Loading character settings: {\"ARGV\":[\"/home/herman/.nvm/versions/node/v23.3.0/bin/node\",\"/mnt/c/Users/Q0V/eliza/agent/src/index.ts\",\"--isRoot\"],\"CWD\":\"/mnt/c/Users/Q0V/eliza/agent\"}\r\n> \r\n> Loaded .env file from: /mnt/c/Users/Q0V/eliza/.env ℹ INFORMATIONS Parsed settings: {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OPENAI_EMBEDDING_TYPE\":\"string\",\"USE_OLLAMA_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"string\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n> \r\n> bigint: Failed to load bindings, pure JS will be used (try npm run rebuild?) using deprecated parameters for the initialization function; pass a single object instead (node:1631) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead. [\"◎ DirectClient constructor\"]\r\n> \r\n> [\"◎ sqlite-vec extensions loaded successfully.\"]\r\n> \r\n> [\"ℹ Using Database Cache...\"]\r\n> \r\n> ✓ SUCCESS SUCCESS Creating runtime for character Eliza\r\n> \r\n> ℹ INFORMATIONS Initializing AgentRuntime with options: {\"character\":\"Eliza\",\"modelProvider\":\"llama_local\",\"characterModelProvider\":\"llama_local\"}\r\n> \r\n> ✓ SUCCESS Agent ID b850bc30-45f8-0041-a00a-83df46d8555d\r\n> \r\n> [\"ℹ Setting model provider...\"]\r\n> \r\n> ℹ INFORMATIONS Model Provider Selection: {\"characterModelProvider\":\"llama_local\",\"optsModelProvider\":\"llama_local\",\"finalSelection\":\"llama_local\"}\r\n> \r\n> ℹ INFORMATIONS Selected model provider: llama_local\r\n> \r\n> ℹ INFORMATIONS Selected image model provider: llama_local\r\n> \r\n> [\"✓ Registering action: CONTINUE\"]\r\n> \r\n> [\"✓ Registering action: FOLLOW_ROOM\"]\r\n> \r\n> [\"✓ Registering action: UNFOLLOW_ROOM\"]\r\n> \r\n> [\"✓ Registering action: IGNORE\"]\r\n> \r\n> [\"✓ Registering action: NONE\"]\r\n> \r\n> [\"✓ Registering action: MUTE_ROOM\"]\r\n> \r\n> [\"✓ Registering action: UNMUTE_ROOM\"]\r\n> \r\n> [\"✓ Registering action: DESCRIBE_IMAGE\"]\r\n> \r\n> ◎ LOGS Registering service: browser\r\n> \r\n> [\"✓ Service browser registered successfully\"]\r\n> \r\n> ◎ LOGS Registering service: image_description\r\n> \r\n> [\"✓ Service image_description registered successfully\"]\r\n> \r\n> ◎ LOGS Registering service: text_generation\r\n> \r\n> [\"✓ Service text_generation registered successfully\"]\r\n> \r\n> ◎ LOGS Registering service: pdf\r\n> \r\n> [\"✓ Service pdf registered successfully\"]\r\n> \r\n> ◎ LOGS Registering service: speech_generation\r\n> \r\n> [\"✓ Service speech_generation registered successfully\"]\r\n> \r\n> ◎ LOGS Registering service: transcription\r\n> \r\n> [\"✓ Service transcription registered successfully\"]\r\n> \r\n> ◎ LOGS Registering service: video\r\n> \r\n> [\"✓ Service video registered successfully\"]\r\n> \r\n> ◎ LOGS Registering service: aws_s3\r\n> \r\n> [\"✓ Service aws_s3 registered successfully\"]\r\n> \r\n> [\"✓ Service browser initialized successfully\"]\r\n> \r\n> [\"◎ Initializing ImageDescriptionService\"]\r\n> \r\n> [\"✓ Service image_description initialized successfully\"]\r\n> \r\n> [\"ℹ Initializing LlamaService...\"]\r\n> \r\n> [\"✓ Service text_generation initialized successfully\"]\r\n> \r\n> [\"✓ Service pdf initialized successfully\"]\r\n> \r\n> [\"✓ Service speech_generation initialized successfully\"]\r\n> \r\n> [\"✓ Service transcription initialized successfully\"]\r\n> \r\n> [\"✓ Service video initialized successfully\"]\r\n> \r\n> Initializing AwsS3Service [\"✓ Service aws_s3 initialized successfully\"]\r\n> \r\n> [\"◎ Initializing ImageDescriptionService\"]\r\n> \r\n> [\"ℹ Initializing LlamaService...\"]\r\n> \r\n> Initializing AwsS3Service ◎ LOGS initializeClients [] for Eliza\r\n> \r\n> ◎ LOGS client keys []\r\n> \r\n> [\"◎ Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port `SERVER_PORT=3001 pnpm start:client`\"]\r\n> \r\n> [\"✓ REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"]\r\n\r\nWSL2 i see \r\nhow much ram do you have on the Linux ? \r\nI start in few seconds on both Linux and Mac\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRDnH",
        "author": "herman-hellenes",
        "body": "Thanks @AIFlowML . I believe WSL have 16gb (computer is 32gb). Too low? \r\n\r\n(when using \"top\" in terminal I get:\r\nMiB Mem :  15828.4 total,  13829.2 free,   1893.9 used,    374.8 buff/cache)\r\n"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k8iQo",
    "number": 1753,
    "title": "Security issue: plugin-0g allows to upload any file",
    "body": "**Describe the bug**\r\n\r\nLooking at 0g plugin, it seems it will allow anyone interacting with the agent to upload **any** file from the filesystem\r\n\r\nhttps://github.com/elizaOS/eliza/blob/main/packages/plugin-0g/src/actions/upload.ts#L111\r\n\r\nThis is potentialyl very dangerous because the attacker could upload .env file, ssh keys or other secrets\r\n\r\n**To Reproduce**\r\n\r\nI have not tried to reproduce this, but it seems pretty obvious that an agent with 0g plugin enabled would not have an issue with uploading any filepath parsed by the template\r\n \r\n**Expected behavior**\r\n\r\nNo private files are uploaded ever.\r\n\r\nThis could involve multiple approaches and risks should be highlighted to agent operator.\r\n\r\nThe template should check for potential security issues (assuming LLMs would generally understand where private files are stored)\r\n![image](https://github.com/user-attachments/assets/4490f256-49f2-4ce5-8b92-9b23f447332c)\r\n\r\nMore secure option would be to limit the `filePath` to some safe subdir, make it configurable in .env and then prefix or match the `filePath` with the prefix\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-03T10:25:35Z",
    "updatedAt": "2025-01-04T06:06:58Z",
    "author": {
      "login": "vpavlin",
      "avatarUrl": "https://avatars.githubusercontent.com/u/4759808?u=d045a41a43fa2deabfc3115236cc1e8b0509b164&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2mOo9g",
        "name": "SECURITY ISSUE",
        "color": "C57E57",
        "description": ""
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZIAxK",
        "author": "vpavlin",
        "body": "cc @lalalune "
      },
      {
        "id": "IC_kwDOMT5cIs6ZMjpY",
        "author": "AIFlowML",
        "body": "I start working on this. "
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k8fUG",
    "number": 1751,
    "title": "pdf js crashes the agent",
    "body": "The agent is crashing when I'm running it due to the error described bellow.\r\nI tried to remove the node module and reinstall them again yet it didn't help\r\n\r\neliza/node_modules/pdfjs-dist/build/pdf.mjs:5764\r\n  var packageCapability = Promise.withResolvers();\r\n                                  ^\r\n\r\nTypeError: Promise.withResolvers is not a function\r\n\r\n\r\n<img width=\"2354\" alt=\"Screenshot 2025-01-03 at 11 09 33 AM\" src=\"https://github.com/user-attachments/assets/e58875f9-03ec-4f09-82bc-b86a6c0a36a5\" />\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-03T10:17:27Z",
    "updatedAt": "2025-01-03T10:50:41Z",
    "author": {
      "login": "virusxd521",
      "avatarUrl": "https://avatars.githubusercontent.com/u/39009219?u=4c6836b85d15f467014728c5df8336da22f285a1&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZH751",
        "author": "github-actions",
        "body": "Hello @virusxd521! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZIGGO",
        "author": "virusxd521",
        "body": "Solved, switched to node v23 instead of 20 and it works"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k8NQB",
    "number": 1747,
    "title": "Jetson Runtime Exception with sqlite-vec Extension Load Failure",
    "body": "**Describe the bug**\r\n\r\nWhen attempting to run an application on Jetson, it fails to load the sqlite-vec extensions. The specific error message suggests that the sqlite-vec-linux-arm64 package might not be installed.\r\n\r\nTo Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nStart the application on Jetson.\r\n```\r\npnpm i && pnpm start\r\n```\r\n\r\n**Expected behavior**\r\nsuccess \r\n\r\n**Screenshots**\r\n<img width=\"1069\" alt=\"image\" src=\"https://github.com/user-attachments/assets/d3fd9d9c-05e7-4e99-8290-f6f479b0f0ff\" />\r\n\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-03T09:25:28Z",
    "updatedAt": "2025-01-03T10:05:37Z",
    "author": {
      "login": "Links17",
      "avatarUrl": "https://avatars.githubusercontent.com/u/61582001?u=a1727eee7f85d47708baf12e85a80cc2d99b01fe&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZHsCS",
        "author": "github-actions",
        "body": "Hello @Links17! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZH4BM",
        "author": "Links17",
        "body": "<img width=\"1083\" alt=\"image\" src=\"https://github.com/user-attachments/assets/65399428-3bb7-440c-9ff0-3fdaf9f25aa2\" />\r\n\r\nIt seems that the issue has been resolved, but a new problem has arisen, so sad.\r\n"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k7zjU",
    "number": 1742,
    "title": "Failed to run on Macbook M1",
    "body": "**Describe the bug**\r\n\r\nI can't run on Macbook M1 using Docker, I follow the same steps on a linux machine and works.\r\n\r\n**To Reproduce**\r\n\r\n`eliza v0.1.6` and build Docker image with Dockerfile. Edited .env with my OpenAI API KEY.\r\nCreated `mainCharacter.ts` under `eliza/agent` path:\r\n```\r\nimport { Character, ModelProviderName, defaultCharacter, Clients } from \"@ai16z/eliza\";\r\n\r\nexport const mainCharacter: Character = {\r\n    ...defaultCharacter,\r\n    clients: [Clients.TWITTER],\r\n    modelProvider: ModelProviderName.OPENAI,\r\n    name: \"agent_cognitive\"\r\n}\r\n```\r\nand import correctly on `eliza/agent/index.ts`\r\n\r\n**Screenshots**\r\n\r\n![imagen](https://github.com/user-attachments/assets/3f5082f5-5109-4dca-8efd-ed94d235a3d9)\r\n\r\n**Additional context**\r\n\r\n\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-03T07:59:39Z",
    "updatedAt": "2025-01-03T08:21:48Z",
    "author": {
      "login": "djpg",
      "avatarUrl": "https://avatars.githubusercontent.com/u/25202539?u=8c804eb1671859cdbae7c8aa3b39cf2378b0c0d1&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZHRD6",
        "author": "github-actions",
        "body": "Hello @djpg! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZHWXT",
        "author": "djpg",
        "body": "Solved following this issue https://github.com/elizaOS/eliza/issues/1543"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k7cu_",
    "number": 1736,
    "title": "Feature Request: Implement Enhanced Error Logging for API Calls",
    "body": "**Is your feature request related to a problem? Please describe.**\n\nThe current logging mechanism does not capture detailed error information when API calls fail, making it difficult to diagnose issues and improve the user experience.\n\n**Describe the solution you'd like**\n\nImplement an enhanced logging system that captures detailed error messages, including the API endpoint, request parameters, and response status codes. This can be achieved by integrating a structured logging library such as Winston or Bunyan.\n\n**Code Example**\n\n```javascript\nconst logger = require('winston');\n\nasync function makeApiCall(endpoint, params) {\n    try {\n        const response = await fetch(endpoint, { method: 'GET', body: JSON.stringify(params) });\n        if (!response.ok) {\n            throw new Error(`API Error: ${response.status} - ${response.statusText}`);\n        }\n        return await response.json();\n    } catch (error) {\n        logger.error('API call failed', { endpoint, params, error: error.message });\n        throw error;\n    }\n}\n```\n\n**Describe alternatives you've considered**\n\nUsing the current logging mechanism, which only captures the error message without context.\n\n**Additional context**\n\nEnhanced logging will provide better visibility into API failures, allowing for quicker diagnosis and resolution of issues, which will ultimately improve the user experience.",
    "state": "CLOSED",
    "createdAt": "2025-01-03T06:27:48Z",
    "updatedAt": "2025-01-03T06:33:24Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB1sfhyA",
        "name": "logging",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7bul",
    "number": 1735,
    "title": "Improve API Error Handling for Coinbase Integration",
    "body": "**Describe the bug**\n\nThe application fails to handle errors gracefully when API calls to Coinbase result in errors, leading to uninformative error messages for users.\n\n**To Reproduce**\n\n1. Attempt to execute a trade with invalid parameters.\n2. Observe the error message displayed to the user.\n\n**Expected behavior**\n\nThe application should provide clear and actionable error messages when an API call fails, allowing users to understand what went wrong and how to fix it.\n\n**Additional context**\n\nImplementing improved error handling will enhance the user experience by providing more informative feedback and reducing confusion when errors occur.\n\n**Related Issues/PRs**\n\n- [Issue #1680](https://github.com/elizaOS/eliza/issues/1680)",
    "state": "OPEN",
    "createdAt": "2025-01-03T06:23:16Z",
    "updatedAt": "2025-01-03T06:23:16Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7bg2",
    "number": 1734,
    "title": "Implement feature for issue #1725 on repository elizaOS/eliza branch develop",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nThe current logging system uses console.log, which leads to inconsistent logging practices and makes it difficult to manage outputs effectively.\n\n**Describe the solution you'd like**\n\nReplace all instances of console.log with elizaLogger.log throughout the codebase to ensure a consistent logging strategy. This will help in maintaining a centralized logging approach and improve the overall logging structure.\n\n**Additional context**\n\nImplementing this change will enhance the maintainability of the codebase and facilitate better logging practices, making it easier to track and analyze logs.",
    "state": "CLOSED",
    "createdAt": "2025-01-03T06:22:17Z",
    "updatedAt": "2025-01-03T06:32:46Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB1sfhyA",
        "name": "logging",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7awD",
    "number": 1733,
    "title": "Issue Created: http proxy error: /e0e10e6f-ff2b-0d4c-8011-1fc1eee7cb32/message",
    "body": "**Describe the bug**\n\nI checkout in main branch and running on WSL2, I have set the WSL2 proxy and it can normally access google.com eg., \nI set the `SERVER_PORT` as my local proxy port 7897.\n1. execute `pnpm start --character=\"characters/trump.character.json\"` and `pnpm start:client` \n2. input some text on dialogue.\nThe `pnpm start:client` terminal show\n```\n9:04:17 AM [vite] http proxy error: /e0e10e6f-ff2b-0d4c-8011-1fc1eee7cb32/message\nError: socket hang up\n    at Socket.socketOnEnd (node:_http_client:542:25)\n    at Socket.emit (node:events:525:35)\n    at endReadableNT (node:internal/streams/readable:1696:12)\n    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)\n```\nThe `pnpm start --character=\"characters/trump.character.json` terminal show\n```\nfile:///home/cxp/solana_learn/AI/eliza/packages/adapter-sqlite/dist/index.js:308\n        const memories = this.db.prepare(sql).all(...queryParams);\n                                              ^\nSqliteError: Error reading 1st vector: zero-length vectors are not supported.\n    at SqliteDatabaseAdapter.searchMemoriesByEmbedding (file:///home/cxp/solana_learn/AI/eliza/packages/adapter-sqlite/dist/index.js:308:47)\n    at SqliteDatabaseAdapter.createMemory (file:///home/cxp/solana_learn/AI/eliza/packages/core/dist/index.js:3176:44)\n    at MemoryManager.createMemory (file:///home/cxp/solana_learn/AI/eliza/packages/core/dist/index.js:240:48)\n    at async file:///home/cxp/solana_learn/AI/eliza/packages/client-direct/dist/index.js:250:13 {\n  code: 'SQLITE_ERROR'\n}\n\nNode.js v23.5.0\n/home/cxp/solana_learn/AI/eliza/agent:\n ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL  @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/trump.character.json\"`\nExit status 1\n```\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\nCan normally access the openai service\n\n**Screenshots**\n\n\r\n**Additional context**\n\n<!-- Add any other context about the problem here. -->",
    "state": "CLOSED",
    "createdAt": "2025-01-03T06:18:52Z",
    "updatedAt": "2025-01-03T19:01:35Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2kKdzw",
        "name": "network",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZKkW1",
        "author": "TovarishFin",
        "body": "I am running into the same issue and i might have a bit more context to add:\r\n\r\nI ran into this while following along with the devschool youtube series. The error started popping up once I started adding something to memory:\r\n\r\n```ts\r\n// ...\r\n            const response = await fetch(\r\n                `https://newsapi.org/v2/everything?q=${searchTerm}&apiKey=${process.env.NEWS_API_KEY}`\r\n            );\r\n            const data = await response.json();\r\n            return data.articles\r\n                .slice(0, 5)\r\n                .map(\r\n                    (article) =>\r\n                        `${article.title}\\n${article.description}\\n${article.content.slice(0, 1000)}`\r\n                )\r\n                .join(\"\\n\\n\");\r\n        }\r\n\r\n        const context = `extract the search term from the user's message. the message is:\r\n        ${message.content.text}\r\n\r\n        only respond with the search term, do not include any other text.`;\r\n\r\n        const searchTerm = await generateText({\r\n            runtime,\r\n            context,\r\n            modelClass: ModelClass.SMALL,\r\n            stop: [\"\\n\"],\r\n        });\r\n\r\n        const currentNews = await getCurrentNews(searchTerm);\r\n        const responseText =\r\n            \"the current news for \" + searchTerm + \" is: \" + currentNews;\r\n\r\n        const newMemory: Memory = {\r\n            userId: message.userId,\r\n            agentId: message.agentId,\r\n            roomId: message.roomId,\r\n            content: {\r\n                text: responseText,\r\n                source: message.content.source,\r\n            } as Content,\r\n        };\r\n\r\n        // offending line of code... probably\r\n        await runtime.messageManager.createMemory(newMemory);\r\n\r\n        callback(newMemory.content);\r\n// ...\r\n```"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k7WRI",
    "number": 1732,
    "title": "Enhance API Documentation",
    "body": "**Is your feature request related to a problem? Please describe.**\n\nThe current API documentation is insufficient and lacks detailed examples.\n\n**Describe the solution you'd like**\n\nImprove the API documentation by adding comprehensive guides and illustrative examples.\n\n**Describe alternatives you've considered**\n\nRelying on the existing documentation.\n\n**Additional context**\n\nBetter documentation will assist developers in effectively integrating with the API.",
    "state": "CLOSED",
    "createdAt": "2025-01-03T05:58:26Z",
    "updatedAt": "2025-01-03T05:59:49Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWw",
        "name": "documentation",
        "color": "0075ca",
        "description": "Improvements or additions to documentation"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7V9m",
    "number": 1731,
    "title": "Implement feature for issue #1725",
    "body": "**Is your feature request related to a problem? Please describe.**\n\nThe current implementation lacks the functionality specified in issue #1725, which is essential for enhancing user experience.\n\n**Describe the solution you'd like**\n\nImplement the feature detailed in issue #1725. This involves modifying the existing codebase to include the new functionality, ensuring that it integrates seamlessly with the current system architecture.\n\n**Describe alternatives you've considered**\n\nConsidering the implementation of a workaround, but that would not provide a long-term solution and could lead to additional technical debt.\n\n**Additional context**\n\nThis feature is critical for meeting user requirements and improving the overall performance of the application. Please refer to issue #1725 for specific details on the required changes.",
    "state": "CLOSED",
    "createdAt": "2025-01-03T05:56:48Z",
    "updatedAt": "2025-01-03T05:59:58Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2kGrJQ",
        "name": "feature request",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7Vv8",
    "number": 1730,
    "title": "Implement feature for issue #1725",
    "body": "**Is your feature request related to a problem? Please describe.**\n\nThe current implementation lacks the functionality specified in issue #1725, which is essential for enhancing user experience.\n\n**Describe the solution you'd like**\n\nImplement the feature detailed in issue #1725. This involves modifying the existing codebase to include the new functionality, ensuring that it integrates seamlessly with the current system architecture.\n\n**Describe alternatives you've considered**\n\nConsidering the implementation of a workaround, but that would not provide a long-term solution and could lead to additional technical debt.\n\n**Additional context**\n\nThis feature is critical for meeting user requirements and improving the overall performance of the application. Please refer to issue #1725 for specific details on the required changes.",
    "state": "CLOSED",
    "createdAt": "2025-01-03T05:55:39Z",
    "updatedAt": "2025-01-03T05:59:41Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2kGfpw",
        "name": "feature",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2kGfqA",
        "name": "development",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7Vb8",
    "number": 1729,
    "title": "Enhance API Documentation",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nThe current API documentation is insufficient and lacks detailed examples.\n\n**Describe the solution you'd like**\n\nImprove the API documentation by adding comprehensive guides and illustrative examples.\n\n**Describe alternatives you've considered**\n\nRelying on the existing documentation.\n\n**Additional context**\n\nBetter documentation will assist developers in effectively integrating with the API.",
    "state": "CLOSED",
    "createdAt": "2025-01-03T05:53:59Z",
    "updatedAt": "2025-01-03T06:00:17Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWw",
        "name": "documentation",
        "color": "0075ca",
        "description": "Improvements or additions to documentation"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7Sj4",
    "number": 1728,
    "title": "Implement Caching for API Responses",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.",
    "state": "OPEN",
    "createdAt": "2025-01-03T05:39:57Z",
    "updatedAt": "2025-01-03T05:39:58Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7SeK",
    "number": 1727,
    "title": "Add documentation for Coinbase SDK integration",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nThe integration of the Coinbase SDK lacks comprehensive documentation, making it challenging for developers to utilize its features effectively.\n\n**Describe the solution you'd like**\n\nCreate detailed documentation for the Coinbase SDK integration, including installation instructions, usage examples, and API reference. This documentation should cover key functionalities such as handling transactions, querying account balances, and managing orders.\n\n**Code Example**\n\n```typescript\nimport { RESTClient } from '@coinbase/coinbase-sdk';\n\nconst client = new RESTClient(process.env.COINBASE_API_KEY, process.env.COINBASE_PRIVATE_KEY);\n\nasync function getAccount() {\n    try {\n        const accounts = await client.listAccounts();\n        console.log(accounts);\n    } catch (error) {\n        console.error('Error fetching accounts:', error);\n    }\n}\n```\n\n**Describe alternatives you've considered**\n\nCurrently, developers rely on trial and error or external resources for guidance, which can lead to confusion and inefficiency.\n\n**Additional context**\n\nProviding thorough documentation will enhance the developer experience, reduce onboarding time, and improve the overall effectiveness of the SDK integration.\n\n**Related Issues/PRs**\n- [Issue #1234](https://github.com/elizaOS/eliza/issues/1234)\n- [PR #5678](https://github.com/elizaOS/eliza/pull/5678)",
    "state": "OPEN",
    "createdAt": "2025-01-03T05:39:27Z",
    "updatedAt": "2025-01-03T06:23:47Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWw",
        "name": "documentation",
        "color": "0075ca",
        "description": "Improvements or additions to documentation"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZG_B0",
        "author": "vishal-kanna",
        "body": "@monilpat I would like to work on it"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k7Qmq",
    "number": 1726,
    "title": "Implement a Caching Mechanism for API Responses",
    "body": "**Is your feature request related to a problem? Please describe.**\n\nThe current application experiences slow response times due to repeated data fetching from external APIs, which can lead to performance bottlenecks.\n\n**Describe the solution you'd like**\n\nImplement a caching mechanism to store and retrieve API responses efficiently. This can be achieved using a caching solution like Redis or Memcached to cache frequently requested data and reduce the load on external API calls.\n\n**Describe alternatives you've considered**\n\nContinuing to fetch data on every request, which results in slower response times and increased server load.\n\n**Additional context**\n\nImplementing caching will significantly enhance the performance of the application, providing a better user experience by ensuring faster load times and reducing the number of requests made to external APIs.\n\n**Related Issues/PRs**\n- [Issue #1663](https://github.com/elizaOS/eliza/issues/1663) - Create GitHub Badges for Community Contributions.\n- [Issue #1677](https://github.com/elizaOS/eliza/issues/1677) - Add HTTP proxy support for AI agent.",
    "state": "CLOSED",
    "createdAt": "2025-01-03T05:28:34Z",
    "updatedAt": "2025-01-03T05:28:51Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7Qd9",
    "number": 1725,
    "title": "Replace console.log with elizaLogger.log",
    "body": "**Is your feature request related to a problem? Please describe.**\n\nThe current implementation uses console.log for logging, which can lead to inconsistent logging practices and makes it difficult to manage log outputs effectively.\n\n**Describe the solution you'd like**\n\nReplace all instances of console.log with elizaLogger.log throughout the codebase to ensure a consistent logging strategy. This will help in maintaining a centralized logging approach and improve the overall logging structure.\n\n**Describe alternatives you've considered**\n\nContinuing to use console.log, but this is not scalable for larger applications and can lead to difficulties in log management.\n\n**Additional context**\n\nImplementing this change will enhance the maintainability of the codebase and facilitate better logging practices, making it easier to track and analyze logs.\n\n**Related Issues/PRs**\n\nNone at this time.",
    "state": "OPEN",
    "createdAt": "2025-01-03T05:27:37Z",
    "updatedAt": "2025-01-03T05:27:38Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB1sfhyA",
        "name": "logging",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7Qc2",
    "number": 1724,
    "title": "Implement a Structured Logging Framework",
    "body": "**Is your feature request related to a problem? Please describe.**\n\nDebugging production issues is difficult due to inconsistent log formats and missing context.\n\n**Describe the solution you'd like**\n\nImplement a structured logging framework that:\n- Uses JSON format for all logs\n- Includes standard fields (timestamp, severity, correlation ID)\n- Supports context injection\n- Has different log levels (DEBUG, INFO, WARN, ERROR)\n- Allows adding custom fields\n- Provides performance logging utilities\n\n**Describe alternatives you've considered**\n- Using plain text logs with grep\n- Manual JSON formatting\n- Application Performance Monitoring (APM) tools only\n\n**Additional context**\nThis would help with:\n- Faster debugging\n- Better monitoring\n- Easier log aggregation\n- Consistent logging patterns",
    "state": "CLOSED",
    "createdAt": "2025-01-03T05:27:31Z",
    "updatedAt": "2025-01-03T05:28:27Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB1sfhyA",
        "name": "logging",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7QZf",
    "number": 1723,
    "title": "Add support for Coinbase Commerce integration",
    "body": "**Is your feature request related to a problem? Please describe.**\n\nCurrently, the application lacks payment processing capabilities through Coinbase Commerce, limiting user interactions and monetization options.\n\n**Describe the solution you'd like**\n\nImplement integration with Coinbase Commerce to allow users to create and manage payment charges directly through the application. This should include functionality for creating charges, checking charge statuses, and handling payments securely.\n\n**Describe alternatives you've considered**\n\nUsing other payment gateways, but they may not align with our existing infrastructure or user base.\n\n**Additional context**\n\nIntegrating with Coinbase Commerce will enhance the application's functionality and provide a seamless payment experience for users.\n\n**Related Issues/PRs**\n- [Issue #1665](https://github.com/elizaOS/eliza/pull/1665) - Adding Twilio plugin for voice interactions.\n- [Issue #1677](https://github.com/elizaOS/eliza/issues/1677) - Request for HTTP proxy support for AI agents.",
    "state": "CLOSED",
    "createdAt": "2025-01-03T05:27:10Z",
    "updatedAt": "2025-01-03T05:28:39Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2kCayw",
        "name": "payment integration",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6k7L0-",
    "number": 1720,
    "title": "Serve docusaurus docs from a docker container for quick docs verification",
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe docs are failing to build because of a typescript error\r\n\r\n**Describe the solution you'd like**\r\n\r\nI'd like to have the docs dir dockerize for quick linting of the docs, validation and quick check.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI prefer to have isolated builds for everything to make sure we have all in CI properly\r\n\r\n**Additional context**\r\n\r\nError while verifying the docs, spending more than an hour to verify that a lot of the dependencies of `docs/package.json` were missing.\r\n\r\nI isolated the docs linter problem to the following file: `docs/packages/plugins.md` \r\n\r\n> **NOTE**: I built a docker image to isolate the problem in a reproducible way.\r\n\r\n```console\r\n    39.56 [webpackbar] ✔ Client: Compiled with some errors in 37.40s\r\n    39.56 [ERROR] Client bundle compiled with errors therefore further build is impossible.\r\n    39.56 Error: MDX compilation failed for file \"/opt/docusaurus/docs/packages/plugins.md\"\r\n    39.56 Cause: Unexpected lazy line in expression in container, expected line to be prefixed with `>` when in a block quote, whitespace when in a list, etc\r\n    39.56 Details:\r\n    39.56 {\r\n    39.56   \"column\": 1,\r\n    39.56   \"message\": \"Unexpected lazy line in expression in container, expected line to be prefixed with `>` when in a block quote, whitespace when in a list, etc\",\r\n    39.56   \"line\": 617,\r\n    39.56   \"name\": \"617:1\",\r\n```",
    "state": "CLOSED",
    "createdAt": "2025-01-03T04:59:29Z",
    "updatedAt": "2025-01-04T01:45:35Z",
    "author": {
      "login": "marcellodesales",
      "avatarUrl": "https://avatars.githubusercontent.com/u/131457?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZLXcR",
        "author": "marcellodesales",
        "body": "I have added PR #1722 to solve the bug and add support for building the docusaurus locally in a docker container:\r\n\r\n* Quick lint of the typescript docs\r\n* Local validation of the server by running it from `docker compose`.\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZLt7n",
        "author": "madjin",
        "body": "merged, closing issue"
      },
      {
        "id": "IC_kwDOMT5cIs6ZLwPo",
        "author": "marcellodesales",
        "body": "@madjin I think I broke the build... I see the develop CI running... I did change a package.json requirement for the documents... "
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6k6swR",
    "number": 1714,
    "title": "can't build framework - followed quick start - pnpm build error",
    "body": "Steps:\r\n\r\n# Clone the repository\r\ngit clone https://github.com/elizaos/eliza.git\r\ncd eliza\r\n\r\ngit checkout $(git describe --tags --abbrev=0)\r\n\r\npnpm install --no-frozen-lockfile\r\n\r\nsuccessful up to here\r\n\r\nfailed the build\r\n\r\npnpm build\r\n\r\n--------------------------------------------------------------------------------------------------------------\r\nError received:\r\n\r\nliza-client:build: ✓ built in 5.48s\r\n@elizaos/plugin-nft-generation:build: DTS ⚡️ Build success in 3926ms\r\n@elizaos/plugin-nft-generation:build: DTS dist/index.d.ts 1.65 KB\r\n@elizaos/client-slack:build: error TS2688: Cannot find type definition file for 'node_tmp_6975'.\r\n@elizaos/client-slack:build:   The file is in the program because:\r\n@elizaos/client-slack:build:     Entry point for implicit type library 'node_tmp_6975'\r\n@elizaos/client-slack:build: \r\n@elizaos/client-slack:build: Error: error occurred in dts build\r\n@elizaos/client-slack:build:     at Worker.<anonymous> (/workspaces/eliza/eliza/node_modules/tsup/dist/index.js:1541:26)\r\n@elizaos/client-slack:build:     at Worker.emit (node:events:513:28)\r\n@elizaos/client-slack:build:     at MessagePort.<anonymous> (node:internal/worker:267:53)\r\n@elizaos/client-slack:build:     at [nodejs.internal.kHybridDispatch] (node:internal/event_target:827:20)\r\n@elizaos/client-slack:build:     at MessagePort.<anonymous> (node:internal/per_context/messageport:23:28)\r\n@elizaos/client-slack:build: DTS Build error\r\n@elizaos/client-slack:build:  ELIFECYCLE  Command failed with exit code 1.\r\n@elizaos/client-slack:build: ERROR: command finished with error: command (/workspaces/eliza/eliza/packages/client-slack) /workspaces/eliza/eliza/node_modules/.bin/pnpm run build exited (1)\r\n@elizaos/client-slack#build: command (/workspaces/eliza/eliza/packages/client-slack) /workspaces/eliza/eliza/node_modules/.bin/pnpm run build exited (1)\r\n\r\n Tasks:    48 successful, 52 total\r\nCached:    46 cached, 52 total\r\n  Time:    8.877s \r\nFailed:    @elizaos/client-slack#build\r\n\r\n ERROR  run failed: command  exited (1)\r\n ELIFECYCLE  Command failed with exit code 1.\r\n\r\n\r\n\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-03T01:22:16Z",
    "updatedAt": "2025-01-03T02:24:05Z",
    "author": {
      "login": "mrosm20",
      "avatarUrl": "https://avatars.githubusercontent.com/u/8084743?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZGX39",
        "author": "github-actions",
        "body": "Hello @mrosm20! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZGYQd",
        "author": "tcm390",
        "body": "hi @mrosm20 did you try this?\r\n\r\n```\r\npnpm clean\r\n\r\npnpm install -r --no-frozen-lockfile\r\n```"
      },
      {
        "id": "IC_kwDOMT5cIs6ZGgAT",
        "author": "mrosm20",
        "body": "thats worked thank you"
      },
      {
        "id": "IC_kwDOMT5cIs6ZGgD0",
        "author": "mrosm20",
        "body": "fixed"
      }
    ]
  }
]
