[
  {
    "id": "I_kwDOMT5cIs6lwsHT",
    "number": 2132,
    "title": "Telegram client - long memory for personal assistent",
    "body": "Just starting working with the framework, maybe it's a basic question: how to keep long memory?\r\n\r\nFor example I want agent to remember something. Then I exchange many new messages. Then I want to get back to the thing I wanted agent to remember. Unfortunately it can only relate to some recent 20-40 (?) messages back.\r\n\r\nIs it a configuration thing? I use default configs.\r\n\r\nor this requires custom plugin that will remember \"todo\" list?\r\n\r\nwhich memory to use for that?\r\n\r\nif there are more items over the time - does it mean the openai or anthropic costs will increase due to bigger context or something similar?\r\n\r\nany ideas how to handle this?",
    "state": "OPEN",
    "createdAt": "2025-01-10T19:51:15Z",
    "updatedAt": "2025-01-10T19:51:15Z",
    "author": {
      "login": "adapt7",
      "avatarUrl": "https://avatars.githubusercontent.com/u/88395064?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lwYFX",
    "number": 2127,
    "title": "â€‰ERR_PNPM_RECURSIVE_RUN_FIRST_FAILâ€‰",
    "body": "**Describe the bug**\r\nâ€‰ERR_PNPM_RECURSIVE_RUN_FIRST_FAILâ€‰ @elizaos/agent@0.1.7 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\r\nExit status 1\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-10T19:14:51Z",
    "updatedAt": "2025-01-10T20:03:18Z",
    "author": {
      "login": "TobiGoldD",
      "avatarUrl": "https://avatars.githubusercontent.com/u/194428446?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Z_9SL",
        "author": "github-actions",
        "body": "Hello @TobiGoldD! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6Z__G6",
        "author": "TobiGoldD",
        "body": "![image](https://github.com/user-attachments/assets/c78b1810-39f0-47f4-8f42-54ee9fa31826)\r\n![ai issue](https://github.com/user-attachments/assets/1dd763b3-497e-4860-a6f0-5ebe90c1b3b4)\r\n\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6aAG-H",
        "author": "brij2001-hof",
        "body": "Are you trying to run in windows environment? \r\nError might or might not be related to the windows environment but if are on Windows, you will need WSL anyway, try to run it in that."
      },
      {
        "id": "IC_kwDOMT5cIs6aAkxx",
        "author": "leyr1112",
        "body": "Please use node version 23.3.\r\nAnd remove node_modules then, pnpm i again."
      },
      {
        "id": "IC_kwDOMT5cIs6aAnV5",
        "author": "TobiGoldD",
        "body": "23.3 is not availible on their web site also this was working for about 6 hours before suddenly stopping with the error\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6aAsfH",
        "author": "leyr1112",
        "body": "What is error, please share screenshot here.\r\nNote for Windows Users: [WSL 2](https://learn.microsoft.com/en-us/windows/wsl/install-manual) is required."
      },
      {
        "id": "IC_kwDOMT5cIs6aAveM",
        "author": "TobiGoldD",
        "body": "![image](https://github.com/user-attachments/assets/fe0064c7-ca0f-4c92-891a-2ec8a6ded428)\r\n\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6aAz64",
        "author": "TobiGoldD",
        "body": "that is the error that comes up when i run pnpm start or npm start\r\n\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6aA1Rg",
        "author": "TobiGoldD",
        "body": "![image](https://github.com/user-attachments/assets/090a6961-aff0-4739-9f23-33c1281db993)\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6aA2EB",
        "author": "TobiGoldD",
        "body": "![image](https://github.com/user-attachments/assets/f6bde072-8b58-49d7-8d8a-97d09c99ee5b)\r\n"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lwC4V",
    "number": 2126,
    "title": " Refactor: Separate Data Providers into Plugins",
    "body": "## Description:\r\nCurrently, the wallet provider contains multiple hardcoded data sources (BirdEye, Codex) which makes the code:\r\nHard to maintain\r\nDifficult to test\r\nIt is not flexible for users who want to use different data sources\r\n\r\n### Proposed Solution:\r\nCreate a plugin system for data providers:\r\n\r\n```\r\n// Example structure:\r\ninterface TokenDataProvider {\r\n    getTokenPrices(tokens: string[]): Promise<Prices>;\r\n    getWalletTokens(wallet: string): Promise<WalletData>;\r\n}\r\n\r\nclass BirdEyeProvider implements TokenDataProvider {\r\n    // BirdEye specific implementation\r\n}\r\n\r\nclass CodexProvider implements TokenDataProvider {\r\n    // Codex specific implementation\r\n}\r\n```\r\n\r\nBenefits:\r\nEasy to add new data providers\r\nUsers can choose their preferred data source\r\n3. Better testing isolation\r\nCleaner code organization\r\n\r\n```\r\nexport class WalletProvider {\r\n    constructor(\r\n        private connection: Connection,\r\n        private walletPublicKey: PublicKey,\r\n        private dataProvider: TokenDataProvider // ðŸ‘ˆ Inject provider\r\n    ) {\r\n        this.cache = new NodeCache({ stdTTL: 300 });\r\n    }\r\n\r\n    async fetchPortfolioValue(runtime): Promise<WalletPortfolio> {\r\n        // Use injected provider instead of hardcoded API calls\r\n        const data = await this.dataProvider.getWalletTokens(\r\n            this.walletPublicKey.toBase58()\r\n        );\r\n        // ... rest of the logic\r\n    }\r\n}\r\n\r\n```",
    "state": "OPEN",
    "createdAt": "2025-01-10T18:33:46Z",
    "updatedAt": "2025-01-10T18:34:09Z",
    "author": {
      "login": "daizhengxue",
      "avatarUrl": "https://avatars.githubusercontent.com/u/47060721?u=51eb13280a596825a4a0b5e4e73a78310eed3fef&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Z_XJQ",
        "author": "github-actions",
        "body": "Hello @daizhengxue! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lva-J",
    "number": 2123,
    "title": "Remove Tavily from core",
    "body": "Right now tavily is being used in core, we want this to be a registered service, not something that is in core",
    "state": "OPEN",
    "createdAt": "2025-01-10T17:06:48Z",
    "updatedAt": "2025-01-10T17:06:48Z",
    "author": {
      "login": "lalalune",
      "avatarUrl": "https://avatars.githubusercontent.com/u/18633264?u=8f2bca0a3cef958bd405ea89680a9b9a0ff38f06&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6luTj9",
    "number": 2116,
    "title": "Tweet reply is sent prior to action processing",
    "body": "**Describe the issue**\r\n\r\nWhen a user interact with agent on twitter, and the agent decide to execute an action, the tweet response is sent immediately and the action is performed afterwards.\r\n\r\n**To Reproduce**\r\n\r\nRead the code, processActions is happening after sendTweet\r\n\r\n**Expected behavior**\r\n\r\nI would expect action processing to happen first then a reply to be sent, potentially with action result. So, if the action is an image generator, the reply tweet would contain the generated image.\r\n\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-10T14:57:09Z",
    "updatedAt": "2025-01-10T17:11:49Z",
    "author": {
      "login": "eschnou",
      "avatarUrl": "https://avatars.githubusercontent.com/u/185660?u=b44df4cc2afad3c9916d80ceb90bdd31a3d722aa&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Z-d43",
        "author": "eschnou",
        "body": "Forget about it, the action is actually processed correctly and the image sent to the user. I had a bug in my code. So the current implementation seems good enough."
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6ltkGL",
    "number": 2114,
    "title": "@elizaos/plugin-twitter has not published in npm",
    "body": "### **Is your feature request related to a problem? Please describe.**\r\nIf you read the Readme of plugin-twitter, you can find this: \r\n\r\n<img width=\"873\" alt=\"image\" src=\"https://github.com/user-attachments/assets/62151833-ee18-4005-92ac-80713fda63f0\" />\r\n\r\nBut it was not published in the npm yet;\r\n\r\n<img width=\"809\" alt=\"image\" src=\"https://github.com/user-attachments/assets/754c46c8-0918-4411-b616-ee334ae1397d\" />\r\n\r\n\r\n### **Describe the solution you'd like**\r\n\r\nPublish it to npm as fast as possible. \r\n\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-10T13:23:49Z",
    "updatedAt": "2025-01-10T17:06:01Z",
    "author": {
      "login": "mameikagou",
      "avatarUrl": "https://avatars.githubusercontent.com/u/116348059?u=ec5d9e06b8ba867a10cf765d5afba55006f355fe&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Z8Pwg",
        "author": "github-actions",
        "body": "Hello @mameikagou! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6Z-bn3",
        "author": "lalalune",
        "body": "Should be fixed soon, try @eliszaos/client-twitter :)"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6ltI2j",
    "number": 2109,
    "title": "[Request] Feature : Response Format",
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCan we implement structured response or response_format defined in a JSON like : [https://platform.openai.com/docs/guides/structured-outputs](https://platform.openai.com/docs/guides/structured-outputs)\r\n\r\n**Describe the solution you'd like**\r\n\r\nA parameter in the settings dict of the character that implements JSON structured response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nHave tried to describe in bio of the character using prompts but quantized(GGUF) models output gibberish sometimes.\r\n\r\n**Additional context**\r\n\r\nI am using LM studio as the OpenAi server and it can give out a structured response to all requests. But that is the problem, agents not requiring JSON output will also follow the instructions which doesn't help if using same local endpoint for multiple agents.",
    "state": "OPEN",
    "createdAt": "2025-01-10T12:26:55Z",
    "updatedAt": "2025-01-10T12:27:19Z",
    "author": {
      "login": "brij2001-hof",
      "avatarUrl": "https://avatars.githubusercontent.com/u/124813487?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Z71Gi",
        "author": "github-actions",
        "body": "Hello @brij2001-hof! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lr_pl",
    "number": 2104,
    "title": "duplicate readme file in packages/plugin-story",
    "body": "**Describe the bug**\r\n\r\nWhen cloning elizaOS/eliza repo, I came across a warning from git command stating there are two conflicting files in the same directory.\r\n![image](https://github.com/user-attachments/assets/5217b11d-9e18-4d2e-a3ec-22cd8a3253aa)\r\n\r\n**To Reproduce**\r\n\r\n1. Run `git clone git@github.com:elizaOS/eliza.git` on a MacOS device\r\n2. You should be able to observe warning from git command\r\n\r\n**Expected behavior**\r\n\r\nSilent clone of repo without any warning.\r\n\r\n**Screenshots**\r\n\r\nScreenshots attached in the Bug Description above.\r\n\r\n**Additional context**\r\n\r\nNA",
    "state": "CLOSED",
    "createdAt": "2025-01-10T09:59:59Z",
    "updatedAt": "2025-01-10T15:23:04Z",
    "author": {
      "login": "KumbleMadhu",
      "avatarUrl": "https://avatars.githubusercontent.com/u/60439370?u=91056b34ed68f9b10ab686d6a52bbcb403501352&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Z6hPf",
        "author": "github-actions",
        "body": "Hello @KumbleMadhu! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6Z9LTX",
        "author": "tcm390",
        "body": "fixed in https://github.com/elizaOS/eliza/commit/7e6d9672ca3422620fae048f52a5b1029bf44188"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lq_wM",
    "number": 2098,
    "title": "Enable Agents to manage Docker Containers",
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nEliza currently lacks the ability to start applications, particularly AI/ML models and services. While Docker containers have become the de facto standard for consistent application deployment across platforms, Eliza cannot leverage this capability. This limitation prevents Eliza from running important tools like Ollama server, managing OSS models, or even maintaining its own model infrastructure in a containerized environment.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd Docker container management capabilities to Eliza agents by integrating Dockerode (TypeScript Docker API client). This would enable agents to:\r\n- Create and manage Docker containers programmatically\r\n- Pull, build, and push Docker images\r\n- Monitor container health and logs\r\n- Execute commands inside containers\r\n- Manage container networks and volumes\r\n- Handle container lifecycle (start, stop, restart, remove)\r\n- Provide a high-level API for container orchestration tasks\r\n\r\n**Describe alternatives you've considered**\r\n\r\nN/A\r\n\r\n**Additional context**\r\n\r\n- Could be integrated with the existing agent capabilities system to add new version of core capabilities\r\n- Would enable automated container-based workflows\r\n- Could serve as foundation for future container orchestration features\r\n- TypeScript types from Dockerode would ensure type safety",
    "state": "OPEN",
    "createdAt": "2025-01-10T07:46:49Z",
    "updatedAt": "2025-01-10T07:46:49Z",
    "author": {
      "login": "bussyjd",
      "avatarUrl": "https://avatars.githubusercontent.com/u/145845?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lq6f2",
    "number": 2096,
    "title": "Eliza Helm Chart to deploy on Kubernetes",
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThere's currently no standardized way to package and distribute Eliza for Kubernetes environments. Users who want to deploy Eliza on Kubernetes have to create their own deployment configurations from scratch, which is time-consuming and can lead to inconsistent deployments across different environments.\r\n\r\n**Describe the solution you'd like**\r\n\r\nCreate a Helm chart for Eliza that would provide:\r\n- A standardized way to package all necessary Kubernetes manifests (deployments, services, configmaps, etc.)\r\n- Configurable values for customizing the deployment (resource limits, replicas, environment variables, etc.)\r\n- Clear documentation on installation and configuration options\r\n- Version-controlled releases that can be easily distributed via Helm repositories\r\n- Support for different deployment scenarios (development, production) through values files\r\n\r\n**Describe alternatives you've considered**\r\n\r\n1. Plain Kubernetes manifests: While this is being addressed in #1711, it requires more manual configuration and doesn't provide the package management benefits of Helm.\r\n2. Kustomize: Could provide environment-specific configurations but lacks the templating and package distribution capabilities of Helm.\r\n3. Operator: Would be overkill for the current deployment needs and would require significantly more development effort.\r\n\r\n**Additional context**\r\n\r\n- This would build upon the existing Docker containerization work\r\n- Could potentially be distributed through the official Helm repository or ArtifactHub\r\n- Would make it easier for organizations to adopt Eliza in their Kubernetes environments\r\n- Aligns with cloud-native best practices for application distribution\r\n- Could include monitoring and observability configurations out of the box",
    "state": "OPEN",
    "createdAt": "2025-01-10T07:33:13Z",
    "updatedAt": "2025-01-10T07:33:13Z",
    "author": {
      "login": "bussyjd",
      "avatarUrl": "https://avatars.githubusercontent.com/u/145845?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lp4Ol",
    "number": 2089,
    "title": "Double responses when interacting on Telegram",
    "body": "**Describe the bug**\r\n\r\nWhenever I am interacting with my agent on Telegram it will occasionally (On a CONTINUE action) respond twice to the same message.\r\n\r\n**To Reproduce**\r\n\r\nRun the Telegram client and talk with the agent. Eventually after a few messages you'll get a double response.\r\n\r\n**Expected behavior**\r\n\r\nNot a double response to the same message.\r\n\r\n**Screenshots**\r\n\r\n<img width=\"897\" alt=\"Screenshot 2025-01-09 at 9 52 47â€¯PM\" src=\"https://github.com/user-attachments/assets/921958ba-f68b-49e8-a5bc-fd6cf6f2d765\" />\r\n<img width=\"898\" alt=\"Screenshot 2025-01-09 at 9 51 15â€¯PM\" src=\"https://github.com/user-attachments/assets/649b3f2e-7e93-49c7-a515-b362176071cc\" />\r\n<img width=\"1397\" alt=\"Screenshot 2025-01-09 at 9 52 18â€¯PM\" src=\"https://github.com/user-attachments/assets/139db3bd-c35d-4b91-b42e-37369b7fc0ad\" />\r\n\r\n\r\n**Additional context**\r\n\r\nRepo: https://github.com/chasebrownn/eliza-fren/tree/frey\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-10T03:53:39Z",
    "updatedAt": "2025-01-10T17:14:10Z",
    "author": {
      "login": "chasebrownn",
      "avatarUrl": "https://avatars.githubusercontent.com/u/54334583?u=a07fa3479e4362c58e6f711bcdf42f819808faf7&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Z4Xgw",
        "author": "github-actions",
        "body": "Hello @chasebrownn! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6Z-Mv-",
        "author": "chuasonglin1995",
        "body": "Hey! The reason is because in the first generated response, the LLM returned action `CONTINUE` and so the action is picked up, and then LLM generated a second response. \r\n\r\nIt's not really a bug, its more of a feature? Like how something you would say multiple lines in a conversations before the other guy replies. According to Shaw himself, he says you get this more often with ChatGPT/ OpenAI. \r\nTry using anthropic, you might see this issue way less often.\r\n\r\nCheers"
      },
      {
        "id": "IC_kwDOMT5cIs6Z-ey8",
        "author": "chasebrownn",
        "body": "I was using Anthropic, but was getting databasing errors due to invalid dimensions so openai was the best alternative. But thank you for the response.\r\n\r\nThe weird thing is the second response isnt really continuing the thread, it's replying 2 times."
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lpaUm",
    "number": 2085,
    "title": "PostgresDB connection Fails sporadically with Large knowledge section.",
    "body": "**Describe the bug**\r\nWhen you have a larger knowledge section, Postgres Supabase connection timeout sporadically.\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n- Create a characterfile\r\n- Load the characterfiles knowledge section with 5 PDFs of large content extracted properly\r\n- Add Postgres URL to env, \"URL\" can be gotten from NeonDB or Supabase (this will allow for the use of Postgres.\r\n- Execute repo with new character file\r\n- Wait a couple of hours for memory creation and embeddings\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n- Embeddings are created successfully like they work when using SQLite (Even though it takes about 8hrs with SQLite)\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\nSnippets from error:\r\n`âš  WARNINGS Database operation failed (attempt 1/10): {\"error\":\"Connection terminated unexpectedly\",\"nextRetryIn\":\"5.6s\"}\r\n\r\nnode:events:491 throw er; // Unhandled 'error' event ^\r\n\r\n<ref *1> Error: read ECONNRESET at TLSWrap.onStreamRead (node:internal/stream_base_commons:216:20) Emitted 'error' event on BoundPool instance at: at Client.idleListener\r\n...\r\n{ errno: -54, code: 'ECONNRESET', syscall: 'read', client: Client { _events: [Object: null prototype] { error: [Function (anonymous)] }, _eventsCount: 1, _maxListeners: undefined, connectionParameters:\r\n`\r\n<!-- Add any other context about the problem here. -->\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-10T01:54:36Z",
    "updatedAt": "2025-01-10T01:55:00Z",
    "author": {
      "login": "joco25",
      "avatarUrl": "https://avatars.githubusercontent.com/u/7952795?u=4444352c94d4a9a092a82e937af40db38003f9b4&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Z38ne",
        "author": "github-actions",
        "body": "Hello @joco25! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      }
    ]
  }
]
