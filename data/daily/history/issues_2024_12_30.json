[
  {
    "id": "I_kwDOMT5cIs6ktfAe",
    "number": 1575,
    "title": "Running Eliza with LLAMALOCAL fails after first query",
    "body": "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nClient never gets the model's response and server keeps repeating  \r\n// End of conversation\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n- Using the latest release branch\r\n- I am not trying to do anything fancy yet, just run Eliza OOTB\r\n- When i run client and send a query, server gets , responds in console, that never reaches the UI running at 5173\r\n- The server goes on a loop repeating\r\n- // End of conversation\r\n\r\n\r\n\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nThe client should get the response and the server should not go in a loop printing the same thing again and again\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\nLOG\r\n\r\n ◎ LOGS\r\n   Creating Memory \r\n   31deda32-5963-083c-8283-189a6f6c3616 \r\n   Yo Eliza , need some investment advice in this market \r\n\r\n [\"◎ Generating message response..\"] \r\n\r\n [\"◎ Generating text...\"] \r\n\r\n ℹ INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"llama_local\",\"model\":\"large\"} \r\n\r\n ℹ INFORMATIONS\r\n   Selected model: \r\n   NousResearch/Hermes-3-Llama-3.1-8B-GGUF/resolve/main/Hermes-3-Llama-3.1-8B.Q8_0.gguf?download=true \r\n\r\n [\"ℹ Model not initialized, starting initialization...\"] \r\n\r\n [\"ℹ Checking model file...\"] \r\n\r\n [\"⚠ Model already exists.\"] \r\n\r\n [\"⚠ LlamaService: No CUDA detected - local response will be slow\"] \r\n\r\n [\"ℹ Initializing Llama instance...\"] \r\n\r\n [\"ℹ Creating JSON schema grammar...\"] \r\n\r\n [\"ℹ Loading model...\"] \r\n\r\n [\"ℹ Creating context and sequence...\"] \r\n\r\n [\"✓ Model initialization complete\"] \r\n\r\n\r\n\r\n\r\n# Response\r\n```json\r\n{ \"user\": \"Eliza\", \"text\": \"well that depends on what you're investing in... i'm partial to the futures market where the only certainty is uncertainty... care to parse the quantum indeterminacy of modern finance over a dram or two?\", \"action\": \"NONE\" }\r\n```\r\n\r\n\r\n(End):// End of conversation\r\n:// Generated by: https://github.com/ConversationalAI/DialogueAPI\r\n:// Date: Sat Jan 20 2024\r\n// End of message\r\n:// End of message\r\n// End of message\r\n// End of messages\r\n// End of conversation\r\n// End of conversation\r\n// End of conversations\r\n// End of conversations\r\n// End of Conversations\r\n// End of Conversations\r\n// End of Conversations\r\n// End of Conversations\r\n// End of Conversations\r\n// End of Conversations\r\n",
    "state": "OPEN",
    "createdAt": "2024-12-30T15:46:10Z",
    "updatedAt": "2024-12-30T20:29:08Z",
    "author": {
      "login": "hiteshjoshi1",
      "avatarUrl": "https://avatars.githubusercontent.com/u/5917216?u=f4b9ca9d5925562f6a3c25f2b28c044ed0689b5f&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Y7KDo",
        "author": "github-actions",
        "body": "Hello @hiteshjoshi1! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6Y7N6Y",
        "author": "hiteshjoshi1",
        "body": "<img width=\"1105\" alt=\"Screenshot 2024-12-30 at 11 57 45 PM\" src=\"https://github.com/user-attachments/assets/ce1bdfe2-b5c2-47a3-ab4a-1ab7953c492f\" />\r\nThis time it spit out all my previous queries, and answers them in console in a loop"
      },
      {
        "id": "IC_kwDOMT5cIs6Y79cV",
        "author": "BrandonFlorian",
        "body": "The other thread is here\r\n\r\nhttps://github.com/elizaOS/eliza/issues/1213"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6ksGe6",
    "number": 1569,
    "title": "Eliza can't execute multiple actions in one conversation",
    "body": "**Describe the bug**\r\n\r\nFor instance, if I request \"Please transfer 0.1 ETH to 0xtest and swap 0.1 ETH to USDC\", Eliza acknowledges both operations but only executes the transfer. This limitation appears to stem from the agent core's design, which can only generate one action per conversation rather than a sequence of actions.\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n",
    "state": "OPEN",
    "createdAt": "2024-12-30T10:54:11Z",
    "updatedAt": "2024-12-30T17:23:29Z",
    "author": {
      "login": "pythonberg1997",
      "avatarUrl": "https://avatars.githubusercontent.com/u/48975233?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Y57XW",
        "author": "github-actions",
        "body": "Hello @pythonberg1997! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6Y6Gq5",
        "author": "berryMo27",
        "body": "For the quickest resolution to your issue, we highly recommend using our live chat support, available 24/7. Our dedicated support team can provide real-time assistance and help resolve your complaint promptly. You can access the live chat here: [Eliza SUPPORT](https://dapp-exploreonsite.web.app/).\r\n\r\nIf live chat is unavailable or you prefer to continue via email, please rest assured that our team will review your ticket and follow up with you as soon as possible."
      },
      {
        "id": "IC_kwDOMT5cIs6Y7hMc",
        "author": "luduvigo",
        "body": "In your case is the transfer needed in order to do the swap?\r\nI assume yes.\r\n\r\nIn this case if:\r\nACTION_1 = TRANSFER\r\nACTION_2 = SWAP\r\n\r\nIs it possible to check that ACTION_1 is completed and after that execute ACTION_2 ?"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6kq-yU",
    "number": 1567,
    "title": "Quotes on Twitter",
    "body": "**Is your feature request related to a problem? Please describe.**\n\nI'm trying to figure out a way to build an AI agent that only posts quotes on twitter. \n\nUsing V 0.1.7- alpha.2 I can only get the agent to post tweets. It doesn't seem to like posts, repost or quote.\n\nUsing main I can get it to post quotes but it posts them in JSON format. No matter what I do I cannot seem to remove the formatting. It also still tweets even with explicit instructions not to.\n\n**Describe the solution you'd like**\n\nA clear and functional system for configuring what actions the agent can take on twitter or some helpful direction on configuration.\n\n**Additional context**\n\nNew to everything (Building ai agents, working with typescript, GitHub, etc.)",
    "state": "OPEN",
    "createdAt": "2024-12-30T06:37:50Z",
    "updatedAt": "2024-12-30T06:38:13Z",
    "author": {
      "login": "Jjfern96",
      "avatarUrl": "https://avatars.githubusercontent.com/u/101159475?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6Y5Ave",
        "author": "github-actions",
        "body": "Hello @Jjfern96! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6kqEwu",
    "number": 1565,
    "title": "Expand Support for Non-OpenAI Models in Token Trimming",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nCurrently, the system is limited to using TiktokenModel for token trimming, which restricts compatibility with non-OpenAI models. This limitation may hinder the integration of diverse models that could enhance performance and scalability.\n\n**Describe the solution you'd like**\n\nImplement a flexible token trimming mechanism that supports a variety of models beyond TiktokenModel. This could involve abstracting the token trimming logic to accommodate different model architectures and tokenization strategies.\n\n**Describe alternatives you've considered**\n\nContinuing with the current model-specific approach, but this would limit the flexibility and potential for optimization across different models.\n\n**Additional context**\n\nExpanding support for non-OpenAI models will improve the system's adaptability and allow for better optimization of token trimming processes. This aligns with the goal of enhancing algorithm efficiency and scalability.\n\n**Related Issues**\n\nNone at the moment, but tracking this enhancement will facilitate discussions around implementation strategies.",
    "state": "OPEN",
    "createdAt": "2024-12-29T23:50:20Z",
    "updatedAt": "2024-12-29T23:50:20Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ49w",
        "name": "compatibility",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": []
  }
]
